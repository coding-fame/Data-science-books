{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29664107",
   "metadata": {},
   "source": [
    "# Model Deployment\n",
    "\n",
    "## 1. What is Model Deployment?\n",
    "\n",
    "Model deployment integrates the trained and tested model into a real-world system, such as an app or website, making it available for use. It’s like serving a finished dish to customers.\n",
    "\n",
    "The process includes:\n",
    "\n",
    "- **Training and Saving the Model**: Build and serialize the model for later use.\n",
    "- **Choosing a Deployment Method**: Decide how to expose the model (e.g., API, cloud, container).\n",
    "- **Ensuring Scalability and Performance**: Handle load and optimize efficiency.\n",
    "- **Monitoring and Maintenance**: Track performance and update the model as needed.\n",
    "\n",
    "---\n",
    "\n",
    "## Deployment Methods\n",
    "\n",
    "There are several ways to deploy a machine learning model in Python. Below, we cover the most popular methods with detailed examples.\n",
    "\n",
    "**Tools and Techniques**\n",
    "- **Flask or FastAPI**: Python frameworks to build web services that serve model predictions via APIs.\n",
    "- **Docker**: Packages the model and its dependencies into a container for consistent deployment across environments.\n",
    "- **Cloud Platforms**: Services like **AWS**, **Google Cloud**, or **Azure** host models at scale with built-in monitoring.\n",
    "- **MLflow**: Manages the model lifecycle, tracking experiments and streamlining deployment.\n",
    "\n",
    "## **Why It’s Important**\n",
    "- **Practical Application**: Deployment turns the model into a tool that solves problems—like filtering spam or recommending products.\n",
    "- **Scalability**: The system must handle many users or requests efficiently.\n",
    "- **Ongoing Performance**: Monitoring ensures the model stays effective as data evolves (e.g., new spam tactics emerge).\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Saving and Loading a Trained Model\n",
    "\n",
    "Before deployment, you need to train and save your model. Python libraries like `scikit-learn`, `TensorFlow`, and `PyTorch` offer serialization options such as `pickle` or `joblib`.\n",
    "\n",
    "### Serialization\n",
    "Serialization converts Python objects into a storable/transmittable byte stream, while deserialization reconstructs objects from this stream. Python provides two primary methods for this:\n",
    "\n",
    "- **Pickle**: Native Python serialization module\n",
    "- **Joblib**: Optimized for large NumPy arrays (common in ML models)\n",
    "\n",
    "Joblib allows you to save and reload models or pipelines efficiently.\n",
    "\n",
    "### Pickling (Serialization)\n",
    "- **Pickling** refers to writing the state of an object to a file.\n",
    "- Convert Python objects to byte streams for storage or transmission.\n",
    "\n",
    "**Key Methods**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95353e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Serialize object to file\n",
    "pickle.dump(obj, file)\n",
    "\n",
    "# Serialize to bytes\n",
    "pickle.dumps(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2044943b",
   "metadata": {},
   "source": [
    "### Unpickling (Deserialization)\n",
    "- Unpickling is the process of reading a pickled file and reconstructing the original Python object.\n",
    "- The predefined function `pickle.load(file)` is used for unpickling.\n",
    "\n",
    "**Key Methods**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a7fd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deserialize from file\n",
    "obj = pickle.load(file)\n",
    "\n",
    "# Deserialize from bytes\n",
    "obj = pickle.loads(bytes_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5d12c7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Example: Training and Saving a Scikit-learn Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc210f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset\n",
    "data = fetch_california_housing()\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save with pickle\n",
    "with open('house_price_model.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "# Alternative: Save with joblib (better for large models)\n",
    "import joblib\n",
    "joblib.dump(model, 'house_price_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cd2f5f",
   "metadata": {},
   "source": [
    "- **Features**: The dataset includes 8 features like `MedInc` (median income), `HouseAge`, `AveRooms`, etc.\n",
    "- **Target**: Median house value.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "| Operation            | Method       | Description                                       |\n",
    "|----------------------|--------------|---------------------------------------------------|\n",
    "| **Pickling**          | `pickle.dump()` | Serialize an object and save it to a file.       |\n",
    "| **Unpickling**        | `pickle.load()` | Load and deserialize the object from a file.     |\n",
    "| **Save with Joblib**  | `joblib.dump()` | Save models efficiently, especially for large models. |\n",
    "| **Load with Joblib**  | `joblib.load()` | Load models saved with Joblib.                   |\n",
    "\n",
    "Pickling and Joblib provide useful ways of saving and loading machine learning models, reducing the need for retraining and improving efficiency.\n",
    "\n",
    "---\n",
    "\n",
    "## Best Practices\n",
    "\n",
    "1. **Version Control**\n",
    "   ```python\n",
    "   import pickle, sys\n",
    "\n",
    "   # Save with version info\n",
    "   metadata = {\n",
    "       'python_version': sys.version,\n",
    "       'library_versions': {\n",
    "           'numpy': np.__version__,\n",
    "           'sklearn': sklearn.__version__\n",
    "       }\n",
    "   }\n",
    "\n",
    "   with open('model.pkl', 'wb') as f:\n",
    "       pickle.dump({'metadata': metadata, 'model': model}, f)\n",
    "   ```\n",
    "\n",
    "2. **Compression with Joblib**\n",
    "   ```python\n",
    "   joblib.dump(model, 'model.joblib', compress=('zlib', 3))\n",
    "   ```\n",
    "\n",
    "3. **Cloud Storage Integration**\n",
    "   ```python\n",
    "   import boto3, joblib\n",
    "\n",
    "   # Save directly to S3\n",
    "   with open('s3://models-bucket/model.joblib', 'wb') as f:\n",
    "       joblib.dump(model, f)\n",
    "   ```\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
