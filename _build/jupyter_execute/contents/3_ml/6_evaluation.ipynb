{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21943a63",
   "metadata": {},
   "source": [
    "# Testing Machine Learning Models\n",
    "\n",
    "## **What Does Testing Machine Learning Models Mean?**\n",
    "\n",
    "Testing the model means evaluating its performance on the separate test set data it hasn’t seen during training. It’s like giving a student a final exam to assess what they’ve learned.\n",
    "The goal is to estimate how well the model will perform in real-world scenarios, ensuring it’s not just memorizing the training data (overfitting) but learning generalizable patterns.\n",
    "\n",
    "## **Why Test Models?**\n",
    "- **Generalization**: Confirm the model works on new, unseen data.\n",
    "- **Performance Metrics**: Quantify accuracy, precision, error rates, etc.\n",
    "- **Model Selection**: Compare different models or configurations.\n",
    "- **Deployment Readiness**: Validate reliability before production use.\n",
    "\n",
    "## **Key Steps**\n",
    "1. **Data Splitting**: Reserve a test set distinct from training and validation data.\n",
    "2. **Prediction**: Use the trained model to predict on the test set.\n",
    "3. **Evaluation**: Compute metrics like accuracy, MSE, or F1-score.\n",
    "4. **Analysis**: Interpret results, identify weaknesses, and refine if needed.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Key Concepts and Methods**\n",
    "\n",
    "### **a. Data Splitting**\n",
    "- **Train-Test Split**: Simple split (e.g., 80-20).\n",
    "- **Train-Validation-Test Split**: Separate validation for tuning (e.g., 70-15-15).\n",
    "- **Cross-Validation**: K-fold testing for robustness.\n",
    "\n",
    "### **b. Evaluation Metrics**\n",
    "- **Classification**:\n",
    "  - Accuracy: \\( \\frac{\\text{correct predictions}}{\\text{total predictions}} \\).\n",
    "  - Precision: \\( \\frac{TP}{TP + FP} \\).\n",
    "  - Recall: \\( \\frac{TP}{TP + FN} \\).\n",
    "  - F1-Score: \\( 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}} \\).\n",
    "  - ROC-AUC: Area under the Receiver Operating Characteristic curve.\n",
    "- **Regression**:\n",
    "  - Mean Squared Error (MSE): \\( \\frac{1}{n} \\sum (y_i - \\hat{y}_i)^2 \\).\n",
    "  - Mean Absolute Error (MAE): \\( \\frac{1}{n} \\sum |y_i - \\hat{y}_i| \\).\n",
    "  - R² Score: Proportion of variance explained.\n",
    "\n",
    "### **c. Testing Strategies**\n",
    "- **Hold-Out Testing**: Single test set evaluation.\n",
    "- **Cross-Validation**: Repeated splits (e.g., 5-fold) for stable estimates.\n",
    "- **Out-of-Time Testing**: For time-series data, test on future periods.\n",
    "\n",
    "### **d. Model Diagnostics**\n",
    "- **Confusion Matrix**: Breakdown of prediction outcomes.\n",
    "- **Learning Curves**: Plot training vs. validation performance.\n",
    "- **Residual Analysis**: Check errors for patterns (regression).\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Tools and Methods Summary**\n",
    "- **Splitting**: `sklearn.model_selection.train_test_split`, `cross_val_score`.\n",
    "- **Metrics**: `sklearn.metrics.accuracy_score`, `mean_squared_error`, `classification_report`.\n",
    "- **Visualization**: `seaborn.heatmap()`, `matplotlib.pyplot.scatter()`.\n",
    "- **Testing**: Model `.predict()`, `.evaluate()` (TensorFlow).\n",
    "\n",
    "---\n",
    "\n",
    "## One-Stop Solution: Reusable Function\n",
    "\n",
    "Here’s a function to streamline testing for any model and task type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf583326",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, task='classification'):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    if task == 'classification':\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap='Blues')\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.show()\n",
    "    elif task == 'regression':\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        print(f\"MSE: {mse:.2f}\")\n",
    "        print(f\"RMSE: {rmse:.2f}\")\n",
    "        print(f\"MAE: {mae:.2f}\")\n",
    "        print(f\"R-squared: {r2:.2f}\")\n",
    "        plt.scatter(y_pred, y_test - y_pred, alpha=0.5)\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Residuals\")\n",
    "        plt.title(\"Residual Plot\")\n",
    "        plt.axhline(y=0, color='r', linestyle='--')\n",
    "        plt.show()\n",
    "    else:\n",
    "        raise ValueError(\"Task must be 'classification' or 'regression'\")\n",
    "    \n",
    "    # Cross-validation\n",
    "    scoring = 'accuracy' if task == 'classification' else 'neg_mean_squared_error'\n",
    "    cv_scores = cross_val_score(model, np.vstack((X_train, X_test)), np.hstack((y_train, y_test)), cv=5, scoring=scoring)\n",
    "    if task == 'regression':\n",
    "        print(f\"Cross-validation MSE: {-cv_scores.mean():.2f} ± {cv_scores.std():.2f}\")\n",
    "    else:\n",
    "        print(f\"Cross-validation Accuracy: {cv_scores.mean():.2f} ± {cv_scores.std():.2f}\")\n",
    "\n",
    "# Example usage\n",
    "# Classification\n",
    "model = LogisticRegression(max_iter=200)\n",
    "evaluate_model(model, X_train, X_test, y_train, y_test, task='classification')  # Iris dataset\n",
    "\n",
    "# Regression\n",
    "model = LinearRegression()\n",
    "evaluate_model(model, X_train, X_test, y_train, y_test, task='regression')  # Housing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dfe1d1",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}