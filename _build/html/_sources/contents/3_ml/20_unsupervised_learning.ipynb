{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8ad33b4",
   "metadata": {},
   "source": [
    "# **Unsupervised Learning**\n",
    "\n",
    "---\n",
    "\n",
    "## **What is Unsupervised Learning?**\n",
    "Unsupervised learning involves training algorithms on **unlabeled data** (data without predefined labels or target variables). \n",
    "\n",
    "The goal is to discover hidden patterns, structures, or relationships without explicit guidance.\n",
    "\n",
    "## **Why Use Unsupervised Learning?**\n",
    "- **No Labels Required**: Ideal when labeled data is scarce or expensive.\n",
    "- **Exploration**: Reveals patterns or anomalies for exploratory data analysis (EDA).\n",
    "- **Dimensionality Reduction**: Simplifies high-dimensional data for visualization or modeling.\n",
    "- **Versatility**: Applicable to diverse tasks (e.g., customer segmentation, feature extraction).\n",
    "\n",
    "## **Key Types**\n",
    "1. **Clustering**: Group similar data points (e.g., customer segmentation).\n",
    "2. **Dimensionality Reduction**: Simplify data while retaining critical information (e.g., visualizing high-dimensional data).\n",
    "3. **Association Rule Learning**: Discover relationships between variables (e.g., \"customers who buy X also buy Y\").\n",
    "4. **Density Estimation**: Model the underlying data distribution (e.g., anomaly detection).\n",
    "\n",
    "---\n",
    "\n",
    "## **Core Techniques and Algorithms**\n",
    "\n",
    "### **A. Clustering**\n",
    "Partitions data into groups based on similarity.\n",
    "\n",
    "**Methods**:\n",
    "- **K-Means**: Divides data into \\( K \\) clusters by minimizing intra-cluster variance.\n",
    "  - *Example*: Segmenting retail customers into groups based on purchase history.\n",
    "- **DBSCAN**: Density-based clustering; identifies outliers as noise.\n",
    "  - *Example*: Detecting fraudulent transactions in finance.\n",
    "- **Hierarchical Clustering**: Builds a tree of clusters (agglomerative or divisive).\n",
    "  - *Example*: Taxonomy creation in biology.\n",
    "- **Gaussian Mixture Models (GMM)**: Soft clustering using probabilistic assignments.\n",
    "  - *Example*: Image compression.\n",
    "\n",
    "### **B. Dimensionality Reduction**\n",
    "Reduces feature count while preserving structure.\n",
    "\n",
    "**Methods**:\n",
    "- **Principal Component Analysis (PCA)**: Linear projection onto orthogonal axes of maximum variance.\n",
    "  - *Example*: Simplifying facial recognition data.\n",
    "- **t-SNE**: Non-linear technique for visualization, preserves local structures.\n",
    "  - *Example*: Visualizing word embeddings in NLP.\n",
    "- **Autoencoders**: Neural networks that compress data into a latent space.\n",
    "  - *Example*: Anomaly detection in manufacturing.\n",
    "\n",
    "### **C. Association Rule Learning**\n",
    "Finds co-occurrence patterns in transactional data.\n",
    "**Methods**:\n",
    "- **Apriori Algorithm**: Identifies frequent itemsets using support and confidence.\n",
    "  - *Example*: Market basket analysis (e.g., \"diapers â†’ beer\").\n",
    "- **Metrics**:\n",
    "  - *Support*: Frequency of an itemset.\n",
    "  - *Confidence*: Likelihood of Y given X.\n",
    "  - *Lift*: Measures independence between items.\n",
    "\n",
    "### **D. Density Estimation**\n",
    "Models the probability distribution of data.\n",
    "- **Kernel Density Estimation (KDE)**: Non-parametric approach.\n",
    "  - *Example*: Estimating population distribution.\n",
    "- **GMM**: Parametric method using Gaussian components.\n",
    "  - *Example*: Speech recognition.\n",
    "\n",
    "---\n",
    "\n",
    "## **Applications**\n",
    "- **Market Segmentation**: Clustering customers for targeted marketing.\n",
    "- **Anomaly Detection**: Identifying outliers in network security.\n",
    "- **Recommendation Systems**: Collaborative filtering using association rules.\n",
    "- **Feature Engineering**: Reducing dimensions before supervised learning.\n",
    "- **Generative Models**: Creating synthetic data (e.g., GANs for art generation).\n",
    "\n",
    "---\n",
    "\n",
    "## **Challenges**\n",
    "- **Evaluation Difficulty**: Lack of labels makes validation subjective.\n",
    "- **Curse of Dimensionality**: High-dimensional data sparsity complicates analysis.\n",
    "- **Interpretability**: Complex patterns may be hard to explain.\n",
    "- **Parameter Sensitivity**: Results depend on hyperparameters (e.g., \\( K \\) in K-means).\n",
    "\n",
    "---\n",
    "\n",
    "## **Evaluation Methods**\n",
    "\n",
    "### **Clustering:**\n",
    "- *Silhouette Score*: Measures cluster cohesion and separation.\n",
    "- *Davies-Bouldin Index*: Lower values indicate better clustering.\n",
    "\n",
    "### **Dimensionality Reduction:**\n",
    "- *Reconstruction Error* (Autoencoders): How well data is rebuilt.\n",
    "- *Downstream Task Performance*: Impact on classification accuracy.\n",
    "\n",
    "### **Association Rules:**\n",
    "- *Lift* and *Conviction*: Assess rule usefulness.\n",
    "\n",
    "---\n",
    "\n",
    "## **Practical Examples**\n",
    "\n",
    "### **Example 1: K-Means Clustering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55edcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Generate synthetic data\n",
    "X, _ = make_blobs(n_samples=300, centers=4, cluster_std=1, random_state=42)\n",
    "df = pd.DataFrame(X, columns=[\"Feature1\", \"Feature2\"])\n",
    "\n",
    "# Fit K-Means\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Visualize\n",
    "plt.scatter(X[:, 0], X[:, 1], c=kmeans.labels_, cmap=\"viridis\", alpha=0.6)\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], \n",
    "            c=\"red\", marker=\"x\", s=200, label=\"Centroids\")\n",
    "plt.title(\"K-Means Clustering (k=4)\")\n",
    "plt.xlabel(\"Feature1\")\n",
    "plt.ylabel(\"Feature2\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Cluster assignments\n",
    "print(\"Cluster Labels:\", kmeans.labels_[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485cf93b",
   "metadata": {},
   "source": [
    "### **Example 2: DBSCAN Clustering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372156e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Fit DBSCAN\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "dbscan.fit(X)\n",
    "\n",
    "# Visualize\n",
    "plt.scatter(X[:, 0], X[:, 1], c=dbscan.labels_, cmap=\"plasma\", alpha=0.6)\n",
    "plt.title(\"DBSCAN Clustering\")\n",
    "plt.xlabel(\"Feature1\")\n",
    "plt.ylabel(\"Feature2\")\n",
    "plt.show()\n",
    "\n",
    "# Labels: -1 indicates noise\n",
    "print(\"Cluster Labels (including noise):\", dbscan.labels_[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44732381",
   "metadata": {},
   "source": [
    "### **Example 3: Principal Component Analysis (PCA)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5622b711",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "df = pd.DataFrame(X, columns=iris.feature_names)\n",
    "\n",
    "# Fit PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Visualize\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=iris.target, cmap=\"coolwarm\", alpha=0.6)\n",
    "plt.title(\"PCA of Iris Dataset (2D)\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.show()\n",
    "\n",
    "# Explained variance\n",
    "print(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)\n",
    "# Output: e.g., [0.924, 0.053]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c26a34a",
   "metadata": {},
   "source": [
    "### **Example 4: t-SNE Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a97d67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Fit t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "\n",
    "# Visualize\n",
    "plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=iris.target, cmap=\"viridis\", alpha=0.6)\n",
    "plt.title(\"t-SNE of Iris Dataset (2D)\")\n",
    "plt.xlabel(\"t-SNE 1\")\n",
    "plt.ylabel(\"t-SNE 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83efe2ad",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Tools and Methods Summary**\n",
    "- **Clustering**: `sklearn.cluster.KMeans`, `DBSCAN`.\n",
    "- **Dimensionality Reduction**: `sklearn.decomposition.PCA`, `sklearn.manifold.TSNE`.\n",
    "- **Evaluation**: `sklearn.metrics.silhouette_score`, `.inertia_` (WCSS for K-Means).\n",
    "- **Visualization**: `matplotlib.pyplot.scatter()`, `seaborn.scatterplot()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e2cb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Evaluate K-Means\n",
    "silhouette = silhouette_score(X, kmeans.labels_)\n",
    "print(\"Silhouette Score for K-Means:\", silhouette)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6c1919",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
