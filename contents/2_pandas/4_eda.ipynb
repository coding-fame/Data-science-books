{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exploratory Data Analysis (EDA) - Complete Guide**\n",
    "\n",
    "## **1. What is EDA?**\n",
    "\n",
    "Exploratory Data Analysis (EDA) is the process of using summary\n",
    "statistics and visualizations to understand, summarize, and investigate\n",
    "a dataset **before building a model**. Its goal is to uncover underlying\n",
    "patterns, spot anomalies, test hypotheses, and check assumptions.\n",
    "\n",
    "### **Core Goals of EDA**\n",
    "\n",
    "-   **Understand** the data‚Äôs structure, variables, and distributions.\n",
    "-   **Clean** the data by handling missing values, duplicates, and\n",
    "    outliers.\n",
    "-   **Discover** relationships, patterns, and trends between variables.\n",
    "-   **Prepare** the data for machine learning with feature engineering\n",
    "    and transformation.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "## **2. The EDA Workflow: A Step-by-Step Guide**\n",
    "\n",
    "The following flowchart outlines a logical progression for your EDA\n",
    "process. You can use this as a checklist:\n",
    "\n",
    "``` mermaid\n",
    "flowchart TD\n",
    "    A[Stage 0:<br>Data Collection] --> B[Stage 1:<br>Data Overview]\n",
    "    B --> C[Stage 2:<br>Data Cleaning]\n",
    "    C --> D[Stage 3:<br>Univariate Analysis]\n",
    "    D --> E[Stage 4:<br>Bivariate/Multivariate Analysis]\n",
    "    E --> F[Stage 5:<br>Feature Engineering]\n",
    "    F --> G[Stage 6:<br>Data Partitioning]\n",
    "```\n",
    "\n",
    "### **üõ†Ô∏è Stage 0: Setup & Data Collection**\n",
    "\n",
    "``` python\n",
    "# Import core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load your dataset\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df[\"target\"] = iris.target\n",
    "```\n",
    "\n",
    "### **üîç Stage 1: Data Overview & Inspection**\n",
    "\n",
    "**Goal:** Get a high-level understanding of the dataset‚Äôs structure and\n",
    "quality.\n",
    "\n",
    "**Actions:** 1. **Dimensions:** `df.shape` 2. **Sample Data:**\n",
    "`df.head()`, `df.tail()`, `df.sample(5)` 3. **Data Types:** `df.info()`\n",
    "4. **Basic Statistics:** `df.describe()` 5. **Check for Duplicates:**\n",
    "`df.duplicated().sum()`\n",
    "\n",
    "``` python\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nData Types:\\n\", df.dtypes)\n",
    "print(\"\\nSummary Statistics:\\n\", df.describe())\n",
    "print(\"\\nMissing Values:\\n\", df.isnull().sum())\n",
    "print(\"\\nDuplicate Rows:\", df.duplicated().sum())\n",
    "```\n",
    "\n",
    "### **üßπ Stage 2: Data Cleaning**\n",
    "\n",
    "**Goal:** Handle data quality issues to ensure robust analysis and\n",
    "modeling.\n",
    "\n",
    "| Issue              | How to Detect                 | Common Solutions                                                                                |\n",
    "|:-----------------------|:-----------------------|:-----------------------|\n",
    "| **Missing Values** | `df.isnull().sum()`           | 1\\. **Drop:** `df.dropna()`<br>2. **Fill:** `df.fillna()`, `df['col'].fillna(df['col'].mean())` |\n",
    "| **Duplicates**     | `df.duplicated().sum()`       | **Drop:** `df.drop_duplicates()`                                                                |\n",
    "| **Outliers**       | Boxplots, IQR Method, Z-score | 1\\. **Cap:** `df['col'].clip(lower, upper)`<br>2. **Remove** or **Transform**                   |\n",
    "\n",
    "**Handling Outliers (IQR Method):**\n",
    "\n",
    "``` python\n",
    "Q1 = df['sepal length (cm)'].quantile(0.25)\n",
    "Q3 = df['sepal length (cm)'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "df['sepal length (cm)'] = df['sepal length (cm)'].clip(lower_bound, upper_bound)\n",
    "```\n",
    "\n",
    "### **üìä Stage 3: Univariate Analysis**\n",
    "\n",
    "**Goal:** Understand the distribution and properties of each variable\n",
    "individually.\n",
    "\n",
    "| Variable Type   | Analysis Methods                                                                                                                                                                |\n",
    "|:-----------------------------------|:-----------------------------------|\n",
    "| **Numerical**   | \\- **Histogram with KDE:** `sns.histplot(data=df, x='col', kde=True)`<br>- **Boxplot:** `sns.boxplot(data=df, x='col')`<br>- **Statistics:** `df['col'].describe()`, `skewness` |\n",
    "| **Categorical** | \\- **Frequency Table:** `df['col'].value_counts()`<br>- **Bar Plot:** `sns.countplot(data=df, x='col')`                                                                         |\n",
    "\n",
    "**Why it‚Äôs important for ML:** - **Skewed Distributions:** Can violate\n",
    "assumptions of models like Linear Regression. May require log/box-cox\n",
    "transformation. - **Class Imbalance:** In classification, a dominant\n",
    "class can lead to a biased model.\n",
    "\n",
    "### **üîó Stage 4: Bivariate & Multivariate Analysis**\n",
    "\n",
    "**Goal:** Explore relationships and interactions between two or more\n",
    "variables.\n",
    "\n",
    "| Analysis Type    | Visualization                                                         | Purpose                                    |\n",
    "|:-----------------------|:-----------------------|:-----------------------|\n",
    "| **Num vs.¬†Num**  | Scatter Plot (`sns.scatterplot`), Correlation Heatmap (`sns.heatmap`) | Find linear/non-linear relationships.      |\n",
    "| **Cat vs.¬†Num**  | Box Plot (`sns.boxplot`), Violin Plot (`sns.violinplot`)              | Compare distributions across categories.   |\n",
    "| **Cat vs.¬†Cat**  | Stacked Bar Chart, Heatmap of Crosstab                                | Check for associations between categories. |\n",
    "| **Multivariate** | Pair Plot (`sns.pairplot`), Scatter Plot with Hue                     | Understand interactions of 3+ variables.   |\n",
    "\n",
    "``` python\n",
    "# Correlation Heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Pair Plot\n",
    "sns.pairplot(df, hue='target') # 'hue' adds color for a categorical variable\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### **‚öôÔ∏è Stage 5: Feature Engineering**\n",
    "\n",
    "**Goal:** Create new features or transform existing ones to improve\n",
    "model performance.\n",
    "\n",
    "| Technique                 | Description                     | Python Example                                                                               |\n",
    "|:-----------------------|:-----------------------|:-----------------------|\n",
    "| **Handling Categorical**  | Convert text to numbers.        | `pd.get_dummies(df)` (One-Hot)<br>`LabelEncoder().fit_transform()` (Label)                   |\n",
    "| **Binning**               | Convert numeric to categorical. | `pd.cut(df['age'], bins=3, labels=['Young', 'Adult', 'Senior'])`                             |\n",
    "| **Scaling**               | Normalize/standardize features. | `StandardScaler().fit_transform(df[['col']])`<br>`MinMaxScaler().fit_transform(df[['col']])` |\n",
    "| **Creating New Features** | Derive new insights.            | `df['total_volume'] = df['length'] * df['width'] * df['height']`                             |\n",
    "| **Date/Time Features**    | Extract time components.        | `df['year'] = pd.to_datetime(df['date']).dt.year`                                            |\n",
    "\n",
    "### **üì¶ Stage 6: Data Partitioning**\n",
    "\n",
    "**Goal:** Split the cleaned and engineered data into training and\n",
    "testing sets to evaluate model performance fairly.\n",
    "\n",
    "``` python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define Features (X) and Target (y)\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Perform the split (e.g., 80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"Training set: {X_train.shape}, Testing set: {X_test.shape}\")\n",
    "```\n",
    "\n",
    "**For Imbalanced Datasets:** Use `StratifiedShuffleSplit` or\n",
    "oversampling techniques like **SMOTE** to maintain the class\n",
    "distribution in the splits.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "## **3. Specialized EDA Topics**\n",
    "\n",
    "### **Time-Series EDA**\n",
    "\n",
    "When your data has a time component (e.g., daily sales): -\n",
    "**Decomposition:** Split into Trend, Seasonality, and Residuals\n",
    "(`seasonal_decompose`). - **Stationarity Check:** Use the Augmented\n",
    "Dickey-Fuller test (`adfuller`). - **Autocorrelation:** Plot ACF and\n",
    "PACF to see how past values influence future ones.\n",
    "\n",
    "### **Key Takeaways & Best Practices**\n",
    "\n",
    "-   **Start Simple:** Always begin with `df.info()` and `df.describe()`.\n",
    "-   **Visualize Everything:** A good plot can reveal what summary\n",
    "    statistics cannot.\n",
    "-   **Document Insights:** Keep a log of your findings, hypotheses, and\n",
    "    actions taken.\n",
    "-   **Iterate:** EDA is not linear. You may clean data, find new\n",
    "    insights, and go back to clean again.\n",
    "-   **Context is King:** Always interpret your findings within the\n",
    "    domain/business context. The same correlation might be meaningful in\n",
    "    one context and spurious in another.\n",
    "\n",
    "This revised structure should make your notes easier to follow and\n",
    "implement. Great work on compiling such detailed content"
   ],
   "id": "42a14256-91c8-446e-92a7-ab6bf11055d3"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
