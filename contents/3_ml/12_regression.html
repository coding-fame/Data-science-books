
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Regression Algorithms &#8212; Data Science Books</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-dropdown.css?v=995e94df" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-bootstrap.min.css?v=21c0b90a" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=d567e03f" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'contents/3_ml/12_regression';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Classification Algorithms" href="13_classification.html" />
    <link rel="prev" title="Supervised Learning" href="11_supervised_learning.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
  
    <p class="title logo__title">Data Science Books</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Machine Learning
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Mathematics</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../0_maths/0_essential.html">Essential Mathematics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../0_maths/1_statistics_fundamentals.html">Statistics Fundamentals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../0_maths/1_descriptive.html">Descriptive Statistics</a></li>








<li class="toctree-l1"><a class="reference internal" href="../0_maths/2_probability.html">Probability Theory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../0_maths/3_inferential.html">Inferential Statistics</a></li>



<li class="toctree-l1"><a class="reference internal" href="../0_maths/4_linear_algebra.html">Linear Algebra</a></li>







<li class="toctree-l1"><a class="reference internal" href="../0_maths/5_calculus.html">Calculus</a></li>







<li class="toctree-l1"><a class="reference internal" href="../0_maths/6_regression_analysis.html">Explanatory and Response Variables</a></li>


</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Core Programming</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../1_python/1_basics.html">Python Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../1_python/2_advanced.html">Advanced Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../1_python/3_data_structures.html">Data Structures</a></li>





<li class="toctree-l1"><a class="reference internal" href="../1_python/4_modules_packages.html">Modules &amp; Packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../1_python/5_functions.html">Functions &amp; Modular Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../1_python/6_oop.html">Object-Oriented Programming</a></li>





<li class="toctree-l1"><a class="reference internal" href="../1_python/8_exceptions.html">Exception Management</a></li>
<li class="toctree-l1"><a class="reference internal" href="../1_python/9_regex.html">Regular Expressions</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Data Wrangling</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../2_numpy/1_numpy.html">NumPy (<strong>Numerical Python</strong>)</a></li>



<li class="toctree-l1"><a class="reference internal" href="../2_pandas/1_series.html">Pandas Series</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2_pandas/2_dataframes.html">Pandas DataFrame</a></li>
















<li class="toctree-l1"><a class="reference internal" href="../2_pandas/3_visualization.html"><strong>What is Data Visualization in Data Science?</strong></a></li>


<li class="toctree-l1"><a class="reference internal" href="../2_pandas/4_eda.html"><strong>What is Exploratory Data Analysis (EDA)?</strong></a></li>






<li class="toctree-l1"><a class="reference internal" href="../2_pandas/5_feature_engineering.html"><strong>What is Feature Engineering?</strong></a></li>


</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Machine Learning</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="1_foundations.html">ML Foundational</a></li>





<li class="toctree-l1"><a class="reference internal" href="2_data_preparation.html">2Ô∏è‚É£ Data Handling</a></li>





<li class="toctree-l1"><a class="reference internal" href="2_train_test_split.html">Train-Test Validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="10_core_algo.html">Core Algo</a></li>
<li class="toctree-l1"><a class="reference internal" href="11_supervised_learning.html"><strong>Supervised Learning</strong></a></li>



<li class="toctree-l1 current active"><a class="current reference internal" href="#">Regression Algorithms</a></li>







<li class="toctree-l1"><a class="reference internal" href="13_classification.html">Classification Algorithms</a></li>

<li class="toctree-l1"><a class="reference internal" href="14_decision_trees.html">Decision Trees</a></li>
<li class="toctree-l1"><a class="reference internal" href="15_ensemble_methods.html">Ensemble Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="16_svm.html">Support Vector Machine (SVM) in Detail</a></li>


<li class="toctree-l1"><a class="reference internal" href="17_knn.html">k-Nearest Neighbors</a></li>
<li class="toctree-l1"><a class="reference internal" href="18_naive_bayes.html">Naive Bayes</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="20_unsupervised_learning.html">Unsupervised Learning</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="21_clustering.html">Clustering Techniques</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="5_model_evaluation.html">4Ô∏è‚É£ Model Evaluation</a></li>




<li class="toctree-l1 has-children"><a class="reference internal" href="6_ml_lifecycle.html">ML Lifecycle</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="6_training.html">Model Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="6_evaluation.html">Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="6_deployment.html">Model Deployment</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="7_optimization_and_training.html">5Ô∏è‚É£ Optimization &amp; Training</a></li>







</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Deep Learning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../4_dl/dl1_Introduction.html">Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../4_dl/dl2_Neuron.html">Neuron</a></li>
<li class="toctree-l1"><a class="reference internal" href="../4_dl/dl3_Libraries.html">Libraries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../4_dl/dl4_Terminology.html">Terminology</a></li>
<li class="toctree-l1"><a class="reference internal" href="../4_dl/dl5_multi_layer.html">Multi-Layer Perceptron (MLP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../4_dl/dl6_first_nn.html">First Neural Network with Keras</a></li>
<li class="toctree-l1"><a class="reference internal" href="../4_dl/dl7_evaluating_model.html">Evaluating Model Performance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../4_dl/dl8_multiclass_classification.html">Multiclass Classification of IRIS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../4_dl/dl9_multiclass_classification_hand.html">Multiclass Classification Handwritten Digits</a></li>
<li class="toctree-l1"><a class="reference internal" href="../4_dl/dl10_saving_and_loading.html">Saving and Loading a Deep Learning Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../4_dl/dl11_checkpointing.html">Checkpointing in Deep Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../4_dl/dl12_visualizing_model_training.html"><strong>Visualizing Model Training History in Deep Learning</strong></a></li>

<li class="toctree-l1"><a class="reference internal" href="../4_dl/dl13_loss_functions_activation_functions_and_optimizers.html">Loss Functions, Activation Functions, and Optimizers</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Natural Language Processing</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../5_nlp/nlp1.html">NLP Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../5_nlp/nlp2.html">Text Wrangling and Cleaning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../5_nlp/nlp3.html">Replacing and Correcting Words</a></li>
<li class="toctree-l1"><a class="reference internal" href="../5_nlp/nlp4.html">Components in NLP</a></li>
<li class="toctree-l1"><a class="reference internal" href="../5_nlp/nlp5.html">Bag of Words, TF, and IDF</a></li>
<li class="toctree-l1"><a class="reference internal" href="../5_nlp/nlp6.html">Twitter Sentiment Analysis using TextBlob</a></li>
<li class="toctree-l1"><a class="reference internal" href="../5_nlp/nlp7.html">NLP with SpaCy</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/contents/3_ml/12_regression.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Regression Algorithms</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Regression Algorithms</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#ml-r-value-and-regression-analysis">ML: R-Value and Regression Analysis</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-regression">üîç Introduction to Regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-the-regression-line">üìà Understanding the Regression Line</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-goal-of-regression">üéØ The Goal of Regression</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#when-to-use-regression">ü§î When to Use Regression?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-r-value">üìå What is R Value?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#r-value-range-interpretation">üìè R Value Range Interpretation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#calculating-r-value-in-python">üßë‚Äçüíª Calculating R Value in Python</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-interpretations">üìä Example Interpretations</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#strong-relationship-regression-is-useful">‚úÖ Strong Relationship (Regression is useful)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#weak-or-no-relationship-regression-is-not-useful">‚ùå Weak or No Relationship (Regression is not useful)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-regression">Linear Regression</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Introduction to Regression</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-linear-regression">What Is Linear Regression?</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#types-of-linear-regression">Types of Linear Regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-linear-regression">Simple Linear Regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multiple-linear-regression">Multiple Linear Regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-concepts">Key Concepts</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#coefficients">1. Coefficients</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#assumptions">2. Assumptions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation-metrics">3. Evaluation Metrics</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#best-fit-line">4. Best Fit line</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#limitations">Limitations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#handling-violations-of-assumptions">Handling Violations of Assumptions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#regularization-techniques">Regularization Techniques</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-linear-predicting-house-price">Simple Linear: Predicting House Price</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-set-up-the-tools">Step 1: Set Up the Tools</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-prepare-the-data">Step 2: Prepare the Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-3-train-the-model">Step 3: Train the Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4-make-a-prediction">Step 4: Make a Prediction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-5-check-the-coefficients">Step 5: Check the Coefficients</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-6-manual-calculation">Step 6: Manual Calculation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualize-the-fit">Visualize the Fit</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#example-multiple-linear-regression">Example: Multiple Linear Regression</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-statement">Problem Statement</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-overview">Dataset Overview</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementing-multiple-linear-regression-in-python">Implementing Multiple Linear Regression in Python</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#making-predictions">Making Predictions</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#example-predicting-california-house-prices"><strong>Example: Predicting California House Prices</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-collection"><strong>1. Data Collection</strong> üóÇÔ∏è</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-preparation"><strong>2. Data Preparation</strong> üîç</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-wrangling"><strong>3. Data Wrangling</strong> üõ†Ô∏è</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#train-the-model"><strong>4. Train the Model</strong> üéØ</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#test-the-model"><strong>5. Test the Model</strong> üß™</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-deployment"><strong>6. Model Deployment</strong> üöÄ</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#ml-polynomial-features">ML: Polynomial Features</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">Overview</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example">Example</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-do-we-need-polynomial-features">Why Do We Need Polynomial Features?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#case-1-linear-data">Case 1: Linear Data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#case-2-non-linear-data">Case 2: Non-Linear Data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-use-polynomial-features"><strong>Why Use Polynomial Features?</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mathematical-representation"><strong>Mathematical Representation</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-simple-linear">Step : Simple Linear</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-concepts-and-methods"><strong>Key Concepts and Methods</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-generating-polynomial-features"><strong>a. Generating Polynomial Features</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#b-polynomial-regression"><strong>b. Polynomial Regression</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#c-interaction-terms"><strong>c. Interaction Terms</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#predictions">Predictions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tools-and-methods-summary"><strong>4. Tools and Methods Summary</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-considerations"><strong>5. Key Considerations</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-interactions-with-polynomial-features">Feature Interactions with Polynomial Features</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Example</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id3"><strong>4. Tools and Methods Summary</strong></a></li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="regression-algorithms">
<h1>Regression Algorithms<a class="headerlink" href="#regression-algorithms" title="Link to this heading">#</a></h1>
</section>
<hr class="docutils" />
<section id="ml-r-value-and-regression-analysis">
<h1>ML: R-Value and Regression Analysis<a class="headerlink" href="#ml-r-value-and-regression-analysis" title="Link to this heading">#</a></h1>
<section id="introduction-to-regression">
<h2>üîç Introduction to Regression<a class="headerlink" href="#introduction-to-regression" title="Link to this heading">#</a></h2>
<p>Regression analysis is a fundamental concept in Machine Learning used to explain the relationship between a <strong>dependent variable</strong> and one or more <strong>independent variables</strong>.</p>
</section>
<hr class="docutils" />
<section id="understanding-the-regression-line">
<h2>üìà Understanding the Regression Line<a class="headerlink" href="#understanding-the-regression-line" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>If two variables are related, we can visualize their relationship in a <strong>two-dimensional space</strong>.</p></li>
<li><p>The result is often a <strong>straight line</strong> that represents their correlation.</p></li>
<li><p>Think of it as plotting scattered points and finding the best possible line to pass through them.</p></li>
</ul>
<hr class="docutils" />
<section id="the-goal-of-regression">
<h3>üéØ The Goal of Regression<a class="headerlink" href="#the-goal-of-regression" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>The primary objective of <strong>Linear Regression</strong> is to draw the <strong>best-fit line</strong>.</p></li>
<li><p>A <strong>best-fit line</strong> is the one that passes as <strong>close as possible</strong> to all data points.</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="when-to-use-regression">
<h2>ü§î When to Use Regression?<a class="headerlink" href="#when-to-use-regression" title="Link to this heading">#</a></h2>
<p><strong>Linear Regression</strong> can only be applied when there is a clear relationship between the variables.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Scenario</p></th>
<th class="head"><p>Can We Use Regression?</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>There is a <strong>strong relationship</strong> between variables</p></td>
<td><p>‚úÖ Yes</p></td>
</tr>
<tr class="row-odd"><td><p>There is <strong>no significant relationship</strong> between variables</p></td>
<td><p>‚ùå No</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<hr class="docutils" />
<section id="what-is-r-value">
<h2>üìå What is R Value?<a class="headerlink" href="#what-is-r-value" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><strong>R value (correlation coefficient)</strong> helps measure how strongly two variables are related.</p></li>
<li><p>It is a critical step in determining whether <strong>Linear Regression</strong> can be applied to a dataset.</p></li>
</ul>
<section id="r-value-range-interpretation">
<h3>üìè R Value Range Interpretation<a class="headerlink" href="#r-value-range-interpretation" title="Link to this heading">#</a></h3>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>R Value</p></th>
<th class="head"><p>Interpretation</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>1.0 or -1.0</strong></p></td>
<td><p>Strong relationship between variables (‚úÖ Regression is applicable)</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Close to 0</strong></p></td>
<td><p>Weak or no relationship (‚ùå Regression is not applicable)</p></td>
</tr>
</tbody>
</table>
</div>
</section>
</section>
<hr class="docutils" />
<section id="calculating-r-value-in-python">
<h2>üßë‚Äçüíª Calculating R Value in Python<a class="headerlink" href="#calculating-r-value-in-python" title="Link to this heading">#</a></h2>
<p>We can use the <strong>scipy.stats</strong> module to compute the R value.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>

<span class="c1"># Example dataset</span>
<span class="n">X</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>

<span class="c1"># Calculate regression statistics</span>
<span class="n">slope</span><span class="p">,</span> <span class="n">intercept</span><span class="p">,</span> <span class="n">r_value</span><span class="p">,</span> <span class="n">p_value</span><span class="p">,</span> <span class="n">std_err</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">linregress</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;R Value:&quot;</span><span class="p">,</span> <span class="n">r_value</span><span class="p">)</span>  <span class="c1"># Output: 1.0 (Strong Relationship)</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="example-interpretations">
<h2>üìä Example Interpretations<a class="headerlink" href="#example-interpretations" title="Link to this heading">#</a></h2>
<section id="strong-relationship-regression-is-useful">
<h3>‚úÖ Strong Relationship (Regression is useful)<a class="headerlink" href="#strong-relationship-regression-is-useful" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Result</strong>: <code class="docutils literal notranslate"><span class="pre">R</span> <span class="pre">Value</span> <span class="pre">=</span> <span class="pre">1.0</span></code></p></li>
<li><p><strong>Conclusion</strong>: A strong relationship exists ‚Üí <strong>Linear Regression can be applied</strong> for future predictions.</p></li>
</ul>
</section>
<section id="weak-or-no-relationship-regression-is-not-useful">
<h3>‚ùå Weak or No Relationship (Regression is not useful)<a class="headerlink" href="#weak-or-no-relationship-regression-is-not-useful" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Result</strong>: <code class="docutils literal notranslate"><span class="pre">R</span> <span class="pre">Value</span> <span class="pre">=</span> <span class="pre">-0.065</span></code></p></li>
<li><p><strong>Conclusion</strong>: The variables are <strong>not related</strong> ‚Üí <strong>Linear Regression will give inaccurate predictions</strong>.</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><strong>Linear regression</strong> is a powerful tool, but it‚Äôs essential to first check if there‚Äôs a <strong>relationship</strong> between the variables.</p></li>
<li><p>The <strong>r value</strong> helps in assessing the strength of this relationship, guiding whether regression is the right approach.</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="linear-regression">
<h1>Linear Regression<a class="headerlink" href="#linear-regression" title="Link to this heading">#</a></h1>
<p>Linear regression is a fundamental algorithm used in <strong>supervised learning</strong> for predicting continuous values.</p>
<section id="id1">
<h2>Introduction to Regression<a class="headerlink" href="#id1" title="Link to this heading">#</a></h2>
<p><strong>Regression analysis</strong> is used to understand the relationship between two variables. It is widely used in data science and machine learning for <strong>predictive modeling</strong>.</p>
</section>
</section>
<section id="what-is-linear-regression">
<h1>What Is Linear Regression?<a class="headerlink" href="#what-is-linear-regression" title="Link to this heading">#</a></h1>
<p><strong>Linear Regression</strong> is a fundamental machine learning technique used to model the relationship between <strong>dependent</strong> and <strong>independent</strong> variables. It helps in predicting outcomes based on input data.</p>
<p>Linear regression assumes that the relationship between variables can be represented by a straight line (or a flat surface in higher dimensions). It‚Äôs widely used because it‚Äôs simple, effective, and provides a strong foundation for more advanced ML techniques.</p>
<section id="types-of-linear-regression">
<h2>Types of Linear Regression<a class="headerlink" href="#types-of-linear-regression" title="Link to this heading">#</a></h2>
<p>There are two main types:</p>
</section>
<section id="simple-linear-regression">
<h2>Simple Linear Regression<a class="headerlink" href="#simple-linear-regression" title="Link to this heading">#</a></h2>
<ul>
<li><p>Uses <strong>one independent variable</strong> (X) to predict <strong>one dependent variable</strong> (Y).</p></li>
<li><p>The goal is to draw a <strong>straight line</strong> that best fits the data, showing how changes in the independent variable affect the dependent variable.</p></li>
<li><p>Example: Predicting house price based on area.</p></li>
<li><p>Formula:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">m</span> <span class="o">*</span> <span class="n">X</span> <span class="o">+</span> <span class="n">b</span>
</pre></div>
</div>
<p>Where:</p>
<ul class="simple">
<li><p><strong>y</strong> = Dependent variable (Predicted output)</p></li>
<li><p><strong>X</strong> = Independent variable (Input feature)</p></li>
<li><p><strong>m</strong> = Slope (Coefficient)</p></li>
<li><p><strong>b</strong> = Intercept (Constant)</p></li>
</ul>
</li>
</ul>
<p>This formula creates a straight line, where <strong>m</strong> controls the tilt and <strong>b</strong> shifts the line up or down.</p>
</section>
<section id="multiple-linear-regression">
<h2>Multiple Linear Regression<a class="headerlink" href="#multiple-linear-regression" title="Link to this heading">#</a></h2>
<ul>
<li><p>Uses <strong>two or more independent variables</strong> (X‚ÇÅ, X‚ÇÇ, ‚Ä¶ X‚Çô) to predict <strong>one dependent variable</strong> (Y).</p></li>
<li><p>The goal is to find the coefficients that define the best-fitting <strong>hyperplane</strong>, minimizing the sum of squared differences between actual and predicted values.</p></li>
<li><p>Example: Predicting house price based on <strong>area, location, and number of bedrooms</strong>.</p></li>
<li><p>Formula:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>y = m‚ÇÅ*X‚ÇÅ + m‚ÇÇ*X‚ÇÇ + .... + m‚Çô*X‚Çô + b
</pre></div>
</div>
<p>Where:</p>
<ul class="simple">
<li><p><strong>Y</strong> = Predicted price</p></li>
<li><p><strong>X‚ÇÅ, X‚ÇÇ, X‚ÇÉ</strong> = Independent variables (Area, Bedrooms, Age)</p></li>
<li><p><strong>m‚ÇÅ, m‚ÇÇ, m‚ÇÉ</strong> = Coefficients (Slope values) (the effect of each x on y)</p></li>
<li><p><strong>b</strong> = Intercept (Bias)</p></li>
</ul>
</li>
</ul>
<p>This formula creates a straight line, where <strong>m</strong> controls the tilt and <strong>b</strong> shifts the line up or down.</p>
</section>
<hr class="docutils" />
<section id="key-concepts">
<h2>Key Concepts<a class="headerlink" href="#key-concepts" title="Link to this heading">#</a></h2>
<section id="coefficients">
<h3>1. Coefficients<a class="headerlink" href="#coefficients" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Slope (m)</strong>: Measures the impact of the independent variable. For example, if m = 135.79, the price increases by $135.79 for each square foot.</p></li>
<li><p><strong>Intercept (b)</strong>: The starting point of the line when x = 0.</p></li>
<li><p>The <strong>intercept (b)</strong> and <strong>coefficients (M‚ÇÅ, M‚ÇÇ, M‚ÇÉ)</strong> define the linear equation.</p></li>
</ul>
</section>
<section id="assumptions">
<h3>2. Assumptions<a class="headerlink" href="#assumptions" title="Link to this heading">#</a></h3>
<p>Simple linear regression works best when:</p>
<ul class="simple">
<li><p>The relationship between x and y is <strong>linear</strong> (a straight line fits).</p></li>
<li><p>Data points are <strong>independent</strong> (one doesn‚Äôt affect another) that is uncorrelated (No Multicollinearity).</p></li>
<li><p>Errors (differences between actual and predicted values) have <strong>constant variance</strong> (Homoscedasticity) and are <strong>normally distributed</strong>.</p></li>
</ul>
</section>
<section id="evaluation-metrics">
<h3>3. Evaluation Metrics<a class="headerlink" href="#evaluation-metrics" title="Link to this heading">#</a></h3>
<p>To check how good the model is:</p>
<ul class="simple">
<li><p><strong>Mean Squared Error (MSE)</strong>: Average of squared differences between actual and predicted values. Lower is better.</p></li>
<li><p><strong>R-squared (R¬≤)</strong>: Shows how much of the data‚Äôs variation the model explains (0 to 1, closer to 1 is better).</p></li>
</ul>
</section>
<section id="best-fit-line">
<h3>4. Best Fit line<a class="headerlink" href="#best-fit-line" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>The ‚Äúbest-fitting‚Äù line is the one that gets as close as possible to all data points.</p></li>
<li><p>In ML, this is done by minimizing the <strong>sum of squared errors (SSE)</strong> the total difference between actual and predicted values.</p></li>
<li><p>The model finds the best-fit line that <strong>minimizes the prediction error</strong>.</p></li>
</ul>
</section>
</section>
<section id="limitations">
<h2>Limitations<a class="headerlink" href="#limitations" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Assumes linearity; struggles with complex non-linear relationships.</p></li>
<li><p>Sensitive to outliers and multicollinearity.</p></li>
<li><p>Requires careful validation of assumptions.</p></li>
</ul>
</section>
<section id="handling-violations-of-assumptions">
<h2>Handling Violations of Assumptions<a class="headerlink" href="#handling-violations-of-assumptions" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><strong>Non-linearity</strong>: Add polynomial/interaction terms.</p></li>
<li><p><strong>Heteroscedasticity</strong>: Use weighted least squares or transform Y.</p></li>
<li><p><strong>Non-normality</strong>: Transform Y (e.g., log transformation).</p></li>
<li><p><strong>Multicollinearity</strong>: Remove correlated variables or use regularization (Ridge/Lasso).</p></li>
</ul>
<section id="regularization-techniques">
<h3>Regularization Techniques<a class="headerlink" href="#regularization-techniques" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Ridge Regression (L2): Shrinks coefficients but does not eliminate them.</p></li>
<li><p>Lasso Regression (L1): Performs feature selection by driving some coefficients to zero.</p></li>
</ul>
</section>
</section>
</section>
<hr class="docutils" />
<section id="simple-linear-predicting-house-price">
<h1>Simple Linear: Predicting House Price<a class="headerlink" href="#simple-linear-predicting-house-price" title="Link to this heading">#</a></h1>
<p>Let‚Äôs use simple linear regression to predict home prices based on their area. Here, <strong>area</strong> is the independent variable (x), and <strong>price</strong> is the dependent variable (y).</p>
<section id="step-1-set-up-the-tools">
<h2>Step 1: Set Up the Tools<a class="headerlink" href="#step-1-set-up-the-tools" title="Link to this heading">#</a></h2>
<p>We‚Äôll use Python and the <strong>Scikit-Learn</strong> library, a popular tool in ML, to build our model.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
</pre></div>
</div>
</section>
<section id="step-2-prepare-the-data">
<h2>Step 2: Prepare the Data<a class="headerlink" href="#step-2-prepare-the-data" title="Link to this heading">#</a></h2>
<p>Imagine we have this data:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Area (sq. ft)</p></th>
<th class="head"><p>Price ($)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1500</p></td>
<td><p>300,000</p></td>
</tr>
<tr class="row-odd"><td><p>1800</p></td>
<td><p>350,000</p></td>
</tr>
<tr class="row-even"><td><p>2000</p></td>
<td><p>400,000</p></td>
</tr>
<tr class="row-odd"><td><p>2200</p></td>
<td><p>420,000</p></td>
</tr>
<tr class="row-even"><td><p>2500</p></td>
<td><p>480,000</p></td>
</tr>
</tbody>
</table>
</div>
<p>We‚Äôll store it in a table (DataFrame) using Python:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;area&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1500</span><span class="p">,</span> <span class="mi">1800</span><span class="p">,</span> <span class="mi">2000</span><span class="p">,</span> <span class="mi">2200</span><span class="p">,</span> <span class="mi">2500</span><span class="p">],</span>
        <span class="s1">&#39;price&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">300000</span><span class="p">,</span> <span class="mi">350000</span><span class="p">,</span> <span class="mi">400000</span><span class="p">,</span> <span class="mi">420000</span><span class="p">,</span> <span class="mi">480000</span><span class="p">]}</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="step-3-train-the-model">
<h2>Step 3: Train the Model<a class="headerlink" href="#step-3-train-the-model" title="Link to this heading">#</a></h2>
<p>We create a linear regression model and train it with our data:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">reg</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">[[</span><span class="s1">&#39;area&#39;</span><span class="p">]],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">])</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">fit()</span></code> finds the best <strong>m</strong> and <strong>b</strong> values to match the data.</p></li>
</ul>
</section>
<section id="step-4-make-a-prediction">
<h2>Step 4: Make a Prediction<a class="headerlink" href="#step-4-make-a-prediction" title="Link to this heading">#</a></h2>
<p>Let‚Äôs predict the price for a house with 3300 sq. ft:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">prediction</span> <span class="o">=</span> <span class="n">reg</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mi">3300</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Predicted price:&quot;</span><span class="p">,</span> <span class="n">prediction</span><span class="p">)</span>
</pre></div>
</div>
<p>This gives us the estimated price based on the trained model.</p>
</section>
<section id="step-5-check-the-coefficients">
<h2>Step 5: Check the Coefficients<a class="headerlink" href="#step-5-check-the-coefficients" title="Link to this heading">#</a></h2>
<p>The model calculates:</p>
<ul class="simple">
<li><p><strong>Slope (m)</strong>: <code class="docutils literal notranslate"><span class="pre">reg.coef_</span></code> (e.g., 135.79)</p></li>
<li><p><strong>Intercept (b)</strong>: <code class="docutils literal notranslate"><span class="pre">reg.intercept_</span></code> (e.g., 180616.44)</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Slope (m):&quot;</span><span class="p">,</span> <span class="n">reg</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Intercept (b):&quot;</span><span class="p">,</span> <span class="n">reg</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="step-6-manual-calculation">
<h2>Step 6: Manual Calculation<a class="headerlink" href="#step-6-manual-calculation" title="Link to this heading">#</a></h2>
<p>Using the formula <code class="docutils literal notranslate"><span class="pre">y</span> <span class="pre">=</span> <span class="pre">m</span> <span class="pre">*</span> <span class="pre">x</span> <span class="pre">+</span> <span class="pre">b</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">m</span> <span class="o">=</span> <span class="n">reg</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">reg</span><span class="o">.</span><span class="n">intercept_</span>
<span class="n">x</span> <span class="o">=</span> <span class="mi">3300</span>
<span class="n">y_manual</span> <span class="o">=</span> <span class="n">m</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">b</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Manual prediction:&quot;</span><span class="p">,</span> <span class="n">y_manual</span><span class="p">)</span>
</pre></div>
</div>
<p>This should match the result from <code class="docutils literal notranslate"><span class="pre">reg.predict()</span></code>.</p>
</section>
<hr class="docutils" />
<section id="visualize-the-fit">
<h2>Visualize the Fit<a class="headerlink" href="#visualize-the-fit" title="Link to this heading">#</a></h2>
<p>We can plot the data and the line:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Area (sq. ft)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Price ($)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;area&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;*&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;area&#39;</span><span class="p">],</span> <span class="n">reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">df</span><span class="p">[[</span><span class="s1">&#39;area&#39;</span><span class="p">]]),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<ul class="simple">
<li><p><strong>Red stars</strong>: Actual data points.</p></li>
<li><p><strong>Blue line</strong>: Predicted values (the best-fitting line).</p></li>
</ul>
<p>This graph shows how well the line fits the data.</p>
</section>
</section>
<hr class="docutils" />
<section id="example-multiple-linear-regression">
<h1>Example: Multiple Linear Regression<a class="headerlink" href="#example-multiple-linear-regression" title="Link to this heading">#</a></h1>
<section id="problem-statement">
<h2>Problem Statement<a class="headerlink" href="#problem-statement" title="Link to this heading">#</a></h2>
<p>Imagine you‚Äôre planning to buy a new house and need to predict the price based on multiple factors:</p>
<ul class="simple">
<li><p><strong>Area (square feet)</strong></p></li>
<li><p><strong>Number of bedrooms</strong></p></li>
<li><p><strong>Age of the house (in years)</strong></p></li>
</ul>
<p>Given the home price dataset, we aim to predict the price of homes with:</p>
<ul class="simple">
<li><p><strong>3000 sq. ft area, 3 bedrooms, 40 years old</strong></p></li>
<li><p><strong>2500 sq. ft area, 4 bedrooms, 5 years old</strong></p></li>
</ul>
</section>
<section id="dataset-overview">
<h2>Dataset Overview<a class="headerlink" href="#dataset-overview" title="Link to this heading">#</a></h2>
<p>We will use <strong>homeprices1.csv</strong> as our dataset, which contains the following columns:</p>
<ul class="simple">
<li><p><strong>Area</strong> (Square Feet)</p></li>
<li><p><strong>Bedrooms</strong> (Number of Bedrooms)</p></li>
<li><p><strong>Age</strong> (Years)</p></li>
<li><p><strong>Price</strong> (Target Variable)</p></li>
</ul>
</section>
<section id="implementing-multiple-linear-regression-in-python">
<h2>Implementing Multiple Linear Regression in Python<a class="headerlink" href="#implementing-multiple-linear-regression-in-python" title="Link to this heading">#</a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">r2_score</span>

<span class="c1"># Load the dataset</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;homeprices1.csv&quot;</span><span class="p">)</span>

<span class="c1"># Handle missing values by filling with median of &#39;bedrooms&#39;</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;bedrooms&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;bedrooms&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">median</span><span class="p">(),</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Separate features and target variable</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;area&#39;</span><span class="p">,</span> <span class="s1">&#39;bedrooms&#39;</span><span class="p">,</span> <span class="s1">&#39;age&#39;</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">]</span>

<span class="c1"># Train the model</span>
<span class="n">reg</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># Display model parameters</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Intercept:&quot;</span><span class="p">,</span> <span class="n">reg</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Coefficients:&quot;</span><span class="p">,</span> <span class="n">reg</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>

<span class="c1"># Predict prices for new homes</span>
<span class="n">new_homes</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;area&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3000</span><span class="p">,</span> <span class="mi">2500</span><span class="p">],</span>
    <span class="s1">&#39;bedrooms&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span>
    <span class="s1">&#39;age&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">40</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="p">})</span>

<span class="n">predicted_prices</span> <span class="o">=</span> <span class="n">reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Predicted Prices:&quot;</span><span class="p">,</span> <span class="n">predicted_prices</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;R¬≤: </span><span class="si">{</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">predicted_prices</span><span class="p">)</span><span class="si">}</span><span class="s2">, RMSE: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">predicted_prices</span><span class="p">))</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="making-predictions">
<h2>Making Predictions<a class="headerlink" href="#making-predictions" title="Link to this heading">#</a></h2>
<p>To predict house prices for new homes:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">predicted_price</span> <span class="o">=</span> <span class="n">reg</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mi">3000</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">40</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Predicted price for 3000 sq.ft, 3 bedrooms, 40 years old: $</span><span class="si">{</span><span class="n">predicted_price</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">,.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">predicted_price</span> <span class="o">=</span> <span class="n">reg</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mi">2500</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Predicted price for 2500 sq.ft, 4 bedrooms, 5 years old: $</span><span class="si">{</span><span class="n">predicted_price</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">,.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<hr class="docutils" />
<section id="example-predicting-california-house-prices">
<h1><strong>Example: Predicting California House Prices</strong><a class="headerlink" href="#example-predicting-california-house-prices" title="Link to this heading">#</a></h1>
<p>We‚Äôll use the <strong>California housing dataset</strong> to predict median house values based on features like median income, house age, and average rooms.</p>
<hr class="docutils" />
<section id="data-collection">
<h2><strong>1. Data Collection</strong> üóÇÔ∏è<a class="headerlink" href="#data-collection" title="Link to this heading">#</a></h2>
<p><strong>Objective</strong>: Gather relevant data for the machine learning task.<br />
<strong>Description</strong>: For this example, we‚Äôll use the California housing dataset, which is available through Scikit-Learn. This dataset includes features such as median income (<code class="docutils literal notranslate"><span class="pre">MedInc</span></code>), house age (<code class="docutils literal notranslate"><span class="pre">HouseAge</span></code>), average number of rooms (<code class="docutils literal notranslate"><span class="pre">AveRooms</span></code>), and others, with the target variable being the median house value (<code class="docutils literal notranslate"><span class="pre">MedHouseVal</span></code>).<br />
<strong>Code</strong>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">fetch_california_housing</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="c1"># Load the dataset</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">fetch_california_housing</span><span class="p">()</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">feature_names</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;MedHouseVal&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span>
</pre></div>
</div>
<p><strong>Explanation</strong>: The <code class="docutils literal notranslate"><span class="pre">fetch_california_housing()</span></code> function retrieves the dataset, and we convert it into a Pandas DataFrame for easier manipulation. The features are stored in <code class="docutils literal notranslate"><span class="pre">data.data</span></code>, and the target variable is in <code class="docutils literal notranslate"><span class="pre">data.target</span></code>. This step simulates collecting data from a reliable source.</p>
</section>
<hr class="docutils" />
<section id="data-preparation">
<h2><strong>2. Data Preparation</strong> üîç<a class="headerlink" href="#data-preparation" title="Link to this heading">#</a></h2>
<p><strong>Objective</strong>: Clean and preprocess the data to make it suitable for modeling.<br />
<strong>Actions</strong>:</p>
<ul class="simple">
<li><p>Check for and handle missing values.</p></li>
<li><p>Select relevant features for the model.</p></li>
<li><p>Scale the features to standardize them for better model performance.</p></li>
</ul>
<p><strong>Code</strong>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Check for missing values</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>  <span class="c1"># No missing values in this dataset</span>

<span class="c1"># Select features and target</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;MedInc&#39;</span><span class="p">,</span> <span class="s1">&#39;HouseAge&#39;</span><span class="p">,</span> <span class="s1">&#39;AveRooms&#39;</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;MedHouseVal&#39;</span><span class="p">]</span>

<span class="c1"># Scale the features</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Explanation</strong>:</p>
<ul class="simple">
<li><p><strong>Missing Values</strong>: The California housing dataset is clean and has no missing values, as confirmed by <code class="docutils literal notranslate"><span class="pre">isnull().sum()</span></code>.</p></li>
<li><p><strong>Feature Selection</strong>: We choose three features‚Äî<code class="docutils literal notranslate"><span class="pre">MedInc</span></code> (median income), <code class="docutils literal notranslate"><span class="pre">HouseAge</span></code> (median house age), and <code class="docutils literal notranslate"><span class="pre">AveRooms</span></code> (average rooms)‚Äîto predict the target <code class="docutils literal notranslate"><span class="pre">MedHouseVal</span></code>.</p></li>
<li><p><strong>Scaling</strong>: <code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code> standardizes the features by removing the mean and scaling to unit variance, which helps the model converge faster and perform better.</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="data-wrangling">
<h2><strong>3. Data Wrangling</strong> üõ†Ô∏è<a class="headerlink" href="#data-wrangling" title="Link to this heading">#</a></h2>
<p><strong>Objective</strong>: Structure and split the data for training and testing.<br />
<strong>Action</strong>: Divide the dataset into training and testing sets to evaluate the model on unseen data.<br />
<strong>Code</strong>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># Split the data into training and testing sets</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Explanation</strong>: We use <code class="docutils literal notranslate"><span class="pre">train_test_split</span></code> to allocate 80% of the data for training (<code class="docutils literal notranslate"><span class="pre">X_train</span></code>, <code class="docutils literal notranslate"><span class="pre">y_train</span></code>) and 20% for testing (<code class="docutils literal notranslate"><span class="pre">X_test</span></code>, <code class="docutils literal notranslate"><span class="pre">y_test</span></code>). The <code class="docutils literal notranslate"><span class="pre">random_state=42</span></code> ensures reproducibility. This step prepares the data for model training and evaluation.</p>
</section>
<hr class="docutils" />
<section id="train-the-model">
<h2><strong>4. Train the Model</strong> üéØ<a class="headerlink" href="#train-the-model" title="Link to this heading">#</a></h2>
<p><strong>Objective</strong>: Build a predictive model using the training data.<br />
<strong>Action</strong>: Train a multiple linear regression model on the selected features.<br />
<strong>Code</strong>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="c1"># Initialize and train the model</span>
<span class="n">reg</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Explanation</strong>: The <code class="docutils literal notranslate"><span class="pre">LinearRegression</span></code> model from Scikit-Learn is used to fit a linear equation to the training data. The <code class="docutils literal notranslate"><span class="pre">fit</span></code> method computes the optimal coefficients for the features (<code class="docutils literal notranslate"><span class="pre">MedInc</span></code>, <code class="docutils literal notranslate"><span class="pre">HouseAge</span></code>, <code class="docutils literal notranslate"><span class="pre">AveRooms</span></code>) to predict <code class="docutils literal notranslate"><span class="pre">MedHouseVal</span></code>.</p>
</section>
<hr class="docutils" />
<section id="test-the-model">
<h2><strong>5. Test the Model</strong> üß™<a class="headerlink" href="#test-the-model" title="Link to this heading">#</a></h2>
<p><strong>Objective</strong>: Evaluate the model‚Äôs performance on the test data.<br />
<strong>Actions</strong>:</p>
<ul class="simple">
<li><p>Generate predictions for the test set.</p></li>
<li><p>Calculate evaluation metrics such as R-squared and Mean Squared Error (MSE).</p></li>
</ul>
<p><strong>Code</strong>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">r2_score</span><span class="p">,</span> <span class="n">mean_squared_error</span>

<span class="c1"># Make predictions on the test set</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Evaluate the model</span>
<span class="n">r2</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">mse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;R-squared:&quot;</span><span class="p">,</span> <span class="n">r2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MSE:&quot;</span><span class="p">,</span> <span class="n">mse</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Explanation</strong>:</p>
<ul class="simple">
<li><p><strong>Predictions</strong>: The <code class="docutils literal notranslate"><span class="pre">predict</span></code> method uses the trained model to estimate house values for the test set.</p></li>
<li><p><strong>Metrics</strong>:</p>
<ul>
<li><p><strong>R-squared</strong>: Measures the proportion of variance in the target variable explained by the model (closer to 1 is better).</p></li>
<li><p><strong>MSE</strong>: Calculates the average squared difference between predicted and actual values (lower is better).<br />
These metrics indicate how well the model generalizes to unseen data.</p></li>
</ul>
</li>
</ul>
</section>
<hr class="docutils" />
<section id="model-deployment">
<h2><strong>6. Model Deployment</strong> üöÄ<a class="headerlink" href="#model-deployment" title="Link to this heading">#</a></h2>
<p><strong>Objective</strong>: Make the trained model available for real-world use.<br />
<strong>Action</strong>: Save the model to a file for later use or deployment.<br />
<strong>Code</strong>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">joblib</span>

<span class="c1"># Save the trained model</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">reg</span><span class="p">,</span> <span class="s1">&#39;california_housing_model.pkl&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Explanation</strong>: The <code class="docutils literal notranslate"><span class="pre">joblib.dump</span></code> function serializes the trained model to a file named <code class="docutils literal notranslate"><span class="pre">california_housing_model.pkl</span></code>. This file can be loaded later to make predictions without retraining. In a real-world scenario, you might deploy this model via a web service (e.g., using Flask or FastAPI), but saving it is a key first step.</p>
</section>
</section>
<hr class="docutils" />
<section id="ml-polynomial-features">
<h1>ML: Polynomial Features<a class="headerlink" href="#ml-polynomial-features" title="Link to this heading">#</a></h1>
<p>Polynomial features extend linear regression by adding terms that are powers or interactions of the original features, allowing the model to fit non-linear patterns. While basic linear regression assumes a straight-line relationship ((y = w_0 + w_1x)), polynomial regression introduces higher-degree terms (e.g., (x^2, x^3)) and interactions (e.g., (x_1x_2)) to model curves and complex dependencies.</p>
<hr class="docutils" />
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Link to this heading">#</a></h2>
<p>Polynomial Features are a type of <strong>feature engineering</strong> where we create new input features based on existing ones by applying polynomial transformations.</p>
<section id="example">
<h3>Example<a class="headerlink" href="#example" title="Link to this heading">#</a></h3>
<p>If we have a dataset with one input feature ( X ), we can create a new feature by squaring ( X ), i.e., ( X^2 ). This process can be extended for higher-degree polynomials:</p>
<ul class="simple">
<li><p><strong>Degree 1:</strong> ( X )</p></li>
<li><p><strong>Degree 2:</strong> ( X, X^2 )</p></li>
<li><p><strong>Degree 3:</strong> ( X, X^2, X^3 ), etc.</p></li>
</ul>
<p>The <strong>degree</strong> of the polynomial controls the number of new features added.</p>
</section>
</section>
<hr class="docutils" />
<section id="why-do-we-need-polynomial-features">
<h2>Why Do We Need Polynomial Features?<a class="headerlink" href="#why-do-we-need-polynomial-features" title="Link to this heading">#</a></h2>
<section id="case-1-linear-data">
<h3>Case 1: Linear Data<a class="headerlink" href="#case-1-linear-data" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>If we apply a <strong>linear model</strong> to <strong>linear data</strong>, it works well (as seen in <strong>Simple Linear Regression</strong>).</p></li>
<li><p>However, if the dataset is <strong>non-linear</strong>, using a linear model <strong>without modification</strong> will produce <strong>poor results</strong>.</p></li>
<li><p>This leads to <strong>high error rates</strong> and inaccurate predictions.</p></li>
</ul>
</section>
<section id="case-2-non-linear-data">
<h3>Case 2: Non-Linear Data<a class="headerlink" href="#case-2-non-linear-data" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>If we use a linear model on <strong>non-linear data</strong>, the predictions will be incorrect.</p></li>
<li><p>This leads to <strong>high error rates</strong> and poor model performance.</p></li>
<li><p><strong>Solution:</strong> Use <strong>Polynomial Regression</strong>, which extends linear regression by adding polynomial terms.</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="why-use-polynomial-features">
<h3><strong>Why Use Polynomial Features?</strong><a class="headerlink" href="#why-use-polynomial-features" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Non-Linearity</strong>: Real-world data often exhibits non-linear relationships (e.g., quadratic growth).</p></li>
<li><p><strong>Flexibility</strong>: Adds expressive power to linear models without changing the algorithm.</p></li>
<li><p><strong>Feature Engineering</strong>: Enhances model performance by capturing more patterns.</p></li>
</ul>
</section>
</section>
<section id="mathematical-representation">
<h2><strong>Mathematical Representation</strong><a class="headerlink" href="#mathematical-representation" title="Link to this heading">#</a></h2>
<p>Simple Linear Regression Equation</p>
<div class="highlight-math notranslate"><div class="highlight"><pre><span></span>y = b_0 + b_1x
</pre></div>
</div>
<p>For a single feature (x), polynomial regression of degree (n) might look like:</p>
<div class="highlight-math notranslate"><div class="highlight"><pre><span></span>y = b_0 + b_1x + b_2x^2 + b_3x^3 + ... + b_nx^n
</pre></div>
</div>
<p>For multiple features (e.g., (x_1, x_2)), it includes interaction terms:</p>
<div class="highlight-math notranslate"><div class="highlight"><pre><span></span>y = b_0 + b_1x_1 + b_2x_2 + b_3x_1^2 + b_4x_1x_2 + b_5x_2^2 + \cdots
</pre></div>
</div>
</section>
<section id="step-simple-linear">
<h2>Step : Simple Linear<a class="headerlink" href="#step-simple-linear" title="Link to this heading">#</a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="c1"># Load the dataset</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;poly_dataset.csv&quot;</span><span class="p">)</span>

<span class="c1"># Extracting independent and dependent variables</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>  <span class="c1"># Selecting feature column</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>    <span class="c1"># Target variable</span>

<span class="c1"># Scatter plot to visualize data distribution</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;blue&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Feature X&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Target y&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Data Distribution&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Train a simple linear regression model</span>
<span class="n">lin_reg</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">lin_reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># Plot the Linear Regression model</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;blue&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">lin_reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Linear Regression Fit&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="key-concepts-and-methods">
<h2><strong>Key Concepts and Methods</strong><a class="headerlink" href="#key-concepts-and-methods" title="Link to this heading">#</a></h2>
<section id="a-generating-polynomial-features">
<h3><strong>a. Generating Polynomial Features</strong><a class="headerlink" href="#a-generating-polynomial-features" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Concept</strong>: Transform original features into a higher-dimensional space with polynomial terms.</p></li>
<li><p><strong>Parameters</strong>:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">degree</span></code>: Maximum power of features.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">interaction_only</span></code>: Include only interaction terms (e.g., (x_1x_2)).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">include_bias</span></code>: Add a constant term (intercept).</p></li>
</ul>
</li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Polynomial features (degree 2)</span>
<span class="n">poly</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">include_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">X_poly</span> <span class="o">=</span> <span class="n">poly</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Original X:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Polynomial X (degree 2):</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">X_poly</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Feature Names:&quot;</span><span class="p">,</span> <span class="n">poly</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">())</span>
</pre></div>
</div>
</section>
<section id="b-polynomial-regression">
<h3><strong>b. Polynomial Regression</strong><a class="headerlink" href="#b-polynomial-regression" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Concept</strong>: Fit a linear model to the polynomial features.</p></li>
<li><p><strong>Steps</strong>: Transform data, then apply linear regression.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">y.ravel()</span></code> vs. <code class="docutils literal notranslate"><span class="pre">y</span></code></strong><br />
If <code class="docutils literal notranslate"><span class="pre">y</span></code> is already a 1D array, <code class="docutils literal notranslate"><span class="pre">.ravel()</span></code> has no effect. If <code class="docutils literal notranslate"><span class="pre">y</span></code> is a column vector (e.g., from a Pandas DataFrame), <code class="docutils literal notranslate"><span class="pre">.ravel()</span></code> reshapes it to avoid warnings/errors.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="c1"># Target: Quadratic relationship y = 2x^2 + x + 1</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]])</span>
<span class="n">y</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">X</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">X</span> <span class="o">+</span> <span class="mi">1</span>

<span class="c1"># Transform</span>
<span class="n">poly</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">X_poly</span> <span class="o">=</span> <span class="n">poly</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Fit model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_poly</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Coefficients:&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>  <span class="c1"># Output: [0, 1, 2] (bias adjusted in intercept)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Intercept:&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>  <span class="c1"># Output: ~1</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;blue&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">poly_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_poly</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Input Feature&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Target Variable&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Polynomial Regression Fit&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="c-interaction-terms">
<h3><strong>c. Interaction Terms</strong><a class="headerlink" href="#c-interaction-terms" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Concept</strong>: Capture relationships between features (e.g., (x_1x_2)).</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Two features</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>

<span class="c1"># Polynomial features with interactions</span>
<span class="n">poly_inter</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">interaction_only</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">include_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">X_poly_inter</span> <span class="o">=</span> <span class="n">poly_inter</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Polynomial with Interactions:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">X_poly_inter</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Feature Names:&quot;</span><span class="p">,</span> <span class="n">poly_inter</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">())</span>
<span class="c1"># Output:</span>
<span class="c1"># [[ 1.  2.  1.  2.  4.]</span>
<span class="c1">#  [ 2.  3.  4.  6.  9.]</span>
<span class="c1">#  [ 3.  4.  9. 12. 16.]]</span>
<span class="c1"># Feature Names: [&#39;x0&#39; &#39;x1&#39; &#39;x0^2&#39; &#39;x0 x1&#39; &#39;x1^2&#39;]</span>
</pre></div>
</div>
</section>
</section>
<section id="predictions">
<h2>Predictions<a class="headerlink" href="#predictions" title="Link to this heading">#</a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Predict output using Linear Regression</span>
<span class="n">linear_pred</span> <span class="o">=</span> <span class="n">lin_reg</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mi">330</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Linear Regression Predicted Output:&quot;</span><span class="p">,</span> <span class="n">linear_pred</span><span class="p">)</span>

<span class="c1"># Predict output using Polynomial Regression</span>
<span class="n">poly_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">poly_reg</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">([[</span><span class="mi">330</span><span class="p">]]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Polynomial Regression Predicted Output:&quot;</span><span class="p">,</span> <span class="n">poly_pred</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p><strong>Linear Regression predicted output:</strong> <code class="docutils literal notranslate"><span class="pre">[330378.78787879]</span></code></p></li>
<li><p><strong>Polynomial Regression predicted output:</strong> <code class="docutils literal notranslate"><span class="pre">[158862.45265155]</span></code></p></li>
<li><p><strong>Polynomial Regression provides a more accurate prediction</strong> in cases where the dataset exhibits <strong>non-linearity</strong>.</p></li>
<li><p>Choosing the right polynomial degree is crucial to avoid <strong>overfitting</strong> or <strong>underfitting</strong>.</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="tools-and-methods-summary">
<h2><strong>4. Tools and Methods Summary</strong><a class="headerlink" href="#tools-and-methods-summary" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><strong>Feature Generation</strong>: <code class="docutils literal notranslate"><span class="pre">sklearn.preprocessing.PolynomialFeatures</span></code>.</p></li>
<li><p><strong>Modeling</strong>: <code class="docutils literal notranslate"><span class="pre">sklearn.linear_model.LinearRegression</span></code>.</p></li>
<li><p><strong>Visualization</strong>: <code class="docutils literal notranslate"><span class="pre">matplotlib.pyplot.plot()</span></code>, <code class="docutils literal notranslate"><span class="pre">scatter()</span></code>.</p></li>
<li><p><strong>Evaluation</strong>: <code class="docutils literal notranslate"><span class="pre">sklearn.metrics.r2_score</span></code> (below).</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">r2_score</span>
<span class="n">r2</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;R¬≤ Score:&quot;</span><span class="p">,</span> <span class="n">r2</span><span class="p">)</span>  <span class="c1"># Measures fit quality</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">Ridge</span>

<span class="c1"># Ridge regression with polynomial features</span>
<span class="n">model_ridge</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">model_ridge</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_poly</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">y_pred_ridge</span> <span class="o">=</span> <span class="n">model_ridge</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_poly</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Ridge Coefficients:&quot;</span><span class="p">,</span> <span class="n">model_ridge</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="key-considerations">
<h2><strong>5. Key Considerations</strong><a class="headerlink" href="#key-considerations" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><strong>Degree Selection</strong>: Higher degrees increase flexibility but risk overfitting.</p></li>
<li><p><strong>Feature Scaling</strong>: Polynomial terms amplify scale differences normalize first.</p></li>
<li><p><strong>Computational Cost</strong>: Number of features grows as ( \binom{n+d}{d} ) (where (n) = features, (d) = degree).</p></li>
<li><p><strong>Regularization</strong>: Use Ridge/Lasso with high-degree polynomials to control overfitting.</p></li>
<li><p><strong>Optimal degree selection</strong> is crucial for balancing bias and variance.</p></li>
</ul>
<p>üìå <strong>Key Takeaway:</strong> Polynomial Regression is a <strong>powerful extension of Linear Regression</strong> that allows models to fit <strong>non-linear data patterns</strong> more effectively.</p>
</section>
<hr class="docutils" />
<section id="feature-interactions-with-polynomial-features">
<h2>Feature Interactions with Polynomial Features<a class="headerlink" href="#feature-interactions-with-polynomial-features" title="Link to this heading">#</a></h2>
<p>Use <code class="docutils literal notranslate"><span class="pre">PolynomialFeatures</span></code> to include feature interactions in your model. However, this is impractical for large datasets and unnecessary for tree-based models.</p>
<section id="id2">
<h3>Example<a class="headerlink" href="#id2" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">PolynomialFeatures</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;A&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="s1">&#39;B&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]})</span>

<span class="c1"># Generate interaction-only features (exclude polynomial terms)</span>
<span class="n">poly</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">include_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">interaction_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">poly</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<hr class="docutils" />
<section id="id3">
<h2><strong>4. Tools and Methods Summary</strong><a class="headerlink" href="#id3" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><strong>Data</strong>: <code class="docutils literal notranslate"><span class="pre">pandas.DataFrame()</span></code>, <code class="docutils literal notranslate"><span class="pre">sklearn.preprocessing.StandardScaler</span></code>.</p></li>
<li><p><strong>Models</strong>: <code class="docutils literal notranslate"><span class="pre">sklearn.linear_model.LogisticRegression</span></code>, <code class="docutils literal notranslate"><span class="pre">tensorflow.keras.models</span></code>.</p></li>
<li><p><strong>Loss</strong>: <code class="docutils literal notranslate"><span class="pre">np.mean()</span></code>, <code class="docutils literal notranslate"><span class="pre">sklearn.metrics.log_loss</span></code>.</p></li>
<li><p><strong>Optimization</strong>: Manual gradient descent, <code class="docutils literal notranslate"><span class="pre">tensorflow.keras.optimizers</span></code>.</p></li>
<li><p><strong>Evaluation</strong>: <code class="docutils literal notranslate"><span class="pre">sklearn.metrics.accuracy_score</span></code>, <code class="docutils literal notranslate"><span class="pre">r2_score</span></code>.</p></li>
<li><p><strong>Regularization</strong>: <code class="docutils literal notranslate"><span class="pre">penalty</span></code> in <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> models.</p></li>
<li><p><strong>Stats</strong>: <code class="docutils literal notranslate"><span class="pre">scipy.stats</span></code>, <code class="docutils literal notranslate"><span class="pre">numpy.random</span></code>.</p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./contents\3_ml"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="11_supervised_learning.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><strong>Supervised Learning</strong></p>
      </div>
    </a>
    <a class="right-next"
       href="13_classification.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Classification Algorithms</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Regression Algorithms</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#ml-r-value-and-regression-analysis">ML: R-Value and Regression Analysis</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-regression">üîç Introduction to Regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-the-regression-line">üìà Understanding the Regression Line</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-goal-of-regression">üéØ The Goal of Regression</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#when-to-use-regression">ü§î When to Use Regression?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-r-value">üìå What is R Value?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#r-value-range-interpretation">üìè R Value Range Interpretation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#calculating-r-value-in-python">üßë‚Äçüíª Calculating R Value in Python</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-interpretations">üìä Example Interpretations</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#strong-relationship-regression-is-useful">‚úÖ Strong Relationship (Regression is useful)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#weak-or-no-relationship-regression-is-not-useful">‚ùå Weak or No Relationship (Regression is not useful)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-regression">Linear Regression</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Introduction to Regression</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-linear-regression">What Is Linear Regression?</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#types-of-linear-regression">Types of Linear Regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-linear-regression">Simple Linear Regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multiple-linear-regression">Multiple Linear Regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-concepts">Key Concepts</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#coefficients">1. Coefficients</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#assumptions">2. Assumptions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation-metrics">3. Evaluation Metrics</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#best-fit-line">4. Best Fit line</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#limitations">Limitations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#handling-violations-of-assumptions">Handling Violations of Assumptions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#regularization-techniques">Regularization Techniques</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-linear-predicting-house-price">Simple Linear: Predicting House Price</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-set-up-the-tools">Step 1: Set Up the Tools</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-prepare-the-data">Step 2: Prepare the Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-3-train-the-model">Step 3: Train the Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4-make-a-prediction">Step 4: Make a Prediction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-5-check-the-coefficients">Step 5: Check the Coefficients</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-6-manual-calculation">Step 6: Manual Calculation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualize-the-fit">Visualize the Fit</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#example-multiple-linear-regression">Example: Multiple Linear Regression</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-statement">Problem Statement</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-overview">Dataset Overview</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementing-multiple-linear-regression-in-python">Implementing Multiple Linear Regression in Python</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#making-predictions">Making Predictions</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#example-predicting-california-house-prices"><strong>Example: Predicting California House Prices</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-collection"><strong>1. Data Collection</strong> üóÇÔ∏è</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-preparation"><strong>2. Data Preparation</strong> üîç</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-wrangling"><strong>3. Data Wrangling</strong> üõ†Ô∏è</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#train-the-model"><strong>4. Train the Model</strong> üéØ</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#test-the-model"><strong>5. Test the Model</strong> üß™</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-deployment"><strong>6. Model Deployment</strong> üöÄ</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#ml-polynomial-features">ML: Polynomial Features</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">Overview</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example">Example</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-do-we-need-polynomial-features">Why Do We Need Polynomial Features?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#case-1-linear-data">Case 1: Linear Data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#case-2-non-linear-data">Case 2: Non-Linear Data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-use-polynomial-features"><strong>Why Use Polynomial Features?</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mathematical-representation"><strong>Mathematical Representation</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-simple-linear">Step : Simple Linear</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-concepts-and-methods"><strong>Key Concepts and Methods</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-generating-polynomial-features"><strong>a. Generating Polynomial Features</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#b-polynomial-regression"><strong>b. Polynomial Regression</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#c-interaction-terms"><strong>c. Interaction Terms</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#predictions">Predictions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tools-and-methods-summary"><strong>4. Tools and Methods Summary</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-considerations"><strong>5. Key Considerations</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-interactions-with-polynomial-features">Feature Interactions with Polynomial Features</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Example</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id3"><strong>4. Tools and Methods Summary</strong></a></li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Gajanesh
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      ¬© Copyright ¬© 2025 Gajanesh. All rights reserved..
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>