
# ML Foundational
---

# üöÄ 1. Introduction to Machine Learning

## ü§ñ What is Machine Learning?
Machine learning is a technique that enables computers to learn automatically from past data without explicit programming.

- **Purpose**: Machine learning helps make predictions based on data by identifying patterns and relationships in it.
- **Example**: Predicting future values based on past data.

### üîç Key Aspects:
- It is an approach to train models.
- It helps predict future values based on past data.

> üß† *Analogy:* Think of ML like a student learning from past exam papers to predict the types of questions in future exams.

---

## üñ•Ô∏è What is a Program?
A program is a group of instructions that a computer executes to perform a specific task.

### ‚úÖ Features:
- Good for simple, well-defined tasks.
- Cannot adapt or improve performance over time.

> üìå *Example:* A calculator program that adds numbers based on predefined logic.

---

## üìú What is an Algorithm?
An algorithm is a set of instructions to perform a task.

| Formula | Explanation |
|---------|------------|
| Input + Logic = Output | A program processes input using logic to produce an output. |
| Data + Program = Result | When applied to data, a program generates results. |

---

## ü§ñ What is a Machine Learning Algorithm?
A Machine Learning (ML) algorithm is a special type of program that learns from data without being explicitly programmed.

| Formula | Explanation |
|---------|------------|
| Data + Result = Program (Model) | The model adjusts itself based on the provided data and results. |

### üîÑ Difference Between Normal & Machine Learning Algorithms
| Feature | Normal Algorithm | Machine Learning Algorithm |
|---------|-----------------|---------------------------|
| Learning Ability | Cannot learn | Learns patterns from data |
| Adaptability | Fixed rules | Adjusts based on input |

---

## üìà Why Machine Learning?
With the massive increase in data generation, ML helps extract valuable insights and make predictions.

### üåç Major Use Cases:
- **Creating models** to solve complex problems.
- **Extracting deep insights** from large datasets.
- **Predicting future trends** based on historical data.

> üöÄ *Future Impact:* Machine learning is poised to be a central element in all industries, shaping the future of technology.

---

## üèõÔ∏è Definitions of Machine Learning
### üî¨ Arthur Samuel‚Äôs Definition (1959):
- Enables machines to learn from data.
- Improves performance based on experiences.
- Makes predictions without explicit programming.

---

## üèÜ AI vs ML vs Deep Learning
| Concept | Definition | Example |
|---------|------------|---------|
| **Artificial Intelligence (AI)** | The ability of computers to mimic human thinking. | Sophia, an advanced AI model. |
| **Machine Learning (ML)** | A subset of AI that allows systems to learn from data. | Netflix recommending shows. |
| **Deep Learning (DL)** | A subset of ML that uses neural networks to mimic human thought. | Self-driving cars. |

---

## üß† Human vs Computer Decision-Making
- **Humans**: make decisions based on experience.
- **Computers**: Use data to create models and make predictions.

### üí° How Do Machines "Think"?
The goal is to make computers think like humans using a three-step process:
1. **Remember:** Analyze massive datasets.
2. **Formulate:** Apply rules and patterns.
3. **Predict:** Use these patterns to make predictions.

---

## üåç Real-World Applications of Machine Learning
### ‚úâÔ∏è **Gmail Spam Filter**
1. The ML algorithm learns from past emails.
2. It creates models based on spam vs. non-spam patterns.
3. It applies these models to new emails to filter spam.

### üè¶ **Banking Loan/Credit Card Approval**
1. A customer applies for a loan, submitting documents (data).
2. The ML algorithm analyzes income, spending, and credit history.
3. It predicts whether the loan should be approved.

---

## üî• Conclusion
Machine learning is transforming industries by automating tasks, making predictions, and extracting valuable insights from data. Its applications will continue to grow, revolutionizing the way we work and interact with technology.

> "Machine Learning isn't the future; it's the present!" üöÄ

---

# 2. Terminology

---

## What is Machine Learning?
Machine Learning (ML) is a technique that enables computers to learn automatically from past data and make predictions or decisions without being explicitly programmed.

### Key Points:
- **Purpose**: Train models to recognize patterns and make future predictions.
- **Applications**: Used in various fields like healthcare, finance, and technology.
- **Example**: Predicting house prices based on historical data.

---

## What is a Model?
A **model** is a simplified representation of reality, created to solve a specific problem.

### Types of Models:
1. **Piece of Code or Program**: A program that processes input data and produces output.
2. **Mathematical Formula**: A set of equations that represent relationships between variables.
3. **Combination of Program + Mathematical Formula**: A hybrid approach that uses both code and equations.

**Example**: A model that predicts weather based on temperature, humidity, and wind speed.

---

## Training the Model
Training a model involves using data to teach it to recognize patterns and make predictions.
- üìå A model **must be trained** using data.
- üéì Training helps the model **learn patterns** from the data.
- üîÑ Before training, the model has **no knowledge** about the patterns.
- üéØ After training, the model understands **patterns** and can make predictions.

**Analogy**:
> *Training a model is like teaching a student to recognize different animal species based on labeled examples.*

---

## How Does the Model Learn?
A model learns by identifying **patterns** in the data.

### Key Concepts:
- **Patterns**: Represent knowledge gained during training.
- **Generalization**: The ability of the model to perform well on unseen data.
- **Feature Extraction**: Identifying important attributes in the data.

**Example**:
- A model trained on images of cats and dogs learns to differentiate between them based on features like shape, size, and color.

---

## Testing the Model
After training, the model must be tested to evaluate its performance.

### Key Steps:
1. **Test Data**: Use new, unseen data to evaluate the model.
2. **Prediction**: Compare the model's predictions with actual results.
3. **Accuracy**: Measure how well the model performs.

**Outcome**:
- **High Accuracy**: The model is ready for deployment.
- **Low Accuracy**: The model needs improvement (e.g., more data, better features).

---

## Model Deployment
Once a model achieves good accuracy, it is deployed for real-world use.
- üìå The trained model is integrated into an application.
- üéØ The model **makes predictions** and **takes decisions** in real-time.
- ü§ñ These deployed models are often referred to as **"model fit."**

**Example**:
- A deployed model in a spam filter application predicts whether an email is spam or not.

---

## What is a Smart Application?
A **smart application** is an application that makes intelligent decisions using machine learning models.

### Comparison:

| **Feature**         | **Normal Application**       | **Smart Application**       |
|---------------------|-----------------------------|-----------------------------|
| **Decision Making** | Based on fixed rules         | Learns and adapts from data |
| **Self-Improvement**| ‚ùå No                        | ‚úÖ Yes                      |
| **Intelligence**    | ‚ùå None                      | ‚úÖ Learns from experience   |

**Example**:
- Gmail uses a smart application to predict whether an email is spam.

---

## Accuracy Testing
Before deployment, a model must be rigorously tested to ensure it performs well in various conditions.

### Key Aspects:
1. **Accuracy**: Measure of correct predictions.
2. **Generalization**: Performance on unseen data.
3. **Edge Cases**: Handling rare or unusual scenarios.

**Outcome**:
- Only models with **high accuracy** are deployed into production.

---

## Key Takeaways
1. **Machine Learning**: Trains models to find patterns and make predictions.
2. **Model**: A simplified representation of reality used to solve problems.
3. **Training**: Teaching the model using data.
4. **Testing**: Evaluating the model's performance on unseen data.
5. **Deployment**: Integrating the model into real-world applications.
6. **Smart Applications**: Use machine learning to make intelligent decisions.
7. **Accuracy Testing**: Ensures the model performs well before deployment.

---

# 3. Learning a Function

---

## Understanding Function Learning in Machine Learning

### What is Learning a Function?
Machine learning algorithms can be understood as **learning a target function (f)** that maps **input variables (X)** to an **output variable (y)**.

#### Mathematical Representation:
```math
Output = f(Input)
y = f(X)
```

However, **real-world data** is often noisy, meaning the function includes some error component.

#### Error Inclusion:
```math
y = f(X) + error
```

---

## Why is Learning a Function Important?
The **goal of function learning** in machine learning is to make **accurate predictions**.

### Key Points:
- A function that has **less error** will make **more accurate predictions**.
- This process is known as **predictive modeling**.

---

## Machine Learning Algorithms
Machine learning algorithms are methods used to **estimate the target function (f)**.

### Key Aspects:
- They help in predicting **output variables (y)** based on **input variables (X)**.
- Different algorithms **assume different forms** for the function, e.g., **linear vs. nonlinear**.

### Types of Function Assumptions

| Algorithm Type   | Assumption about Function (f) |
|------------------|--------------------------------|
| **Linear Models** | Assume a straight-line relationship (e.g., Linear Regression) |
| **Nonlinear Models** | Assume a complex, curved relationship (e.g., Neural Networks) |

---

## Real-World Analogy: Predicting House Prices
Imagine you want to predict the **price of a house** based on factors like **size, location, and number of bedrooms**.

### Input Variables (X):
- `X1 = House Size (sq ft)`
- `X2 = Location` 
- `X3 = Number of Bedrooms`

### Output Variable (y):
- `y = Predicted House Price`

**If the function learned by the model is accurate, it will predict house prices close to real values!**

---

## Interactive Code Example

```python
# Import necessary libraries
import numpy as np
from sklearn.linear_model import LinearRegression

# Sample Data (House Size vs. Price)
X = np.array([[1000], [1500], [2000], [2500], [3000]]) # Input (Size in sq ft)
y = np.array([150000, 200000, 250000, 300000, 350000]) # Output (Price in $)

# Train a Linear Regression Model
model = LinearRegression()
model.fit(X, y)

# Predict the price of a 2200 sq ft house
predicted_price = model.predict([[2200]])
print(f"Predicted House Price: ${predicted_price[0]:,.2f}")
```

---

## Interview Prep: Common Questions & Concepts

### 1. What is a target function in ML?
   - A mathematical relationship that maps inputs (`X`) to an output (`y`).

### 2. Why does the error exist in function learning?
   - Due to noise, missing data, or limitations in the model.

### 3. What is the difference between linear and nonlinear function assumptions?
   - **Linear Models:** Assume a direct proportional relationship.
   - **Nonlinear Models:** Allow for more complex, flexible relationships.

---

## Success Metrics: How to Evaluate a Learned Function?

| Metric       | Description |
|--------------|-------------|
| **Mean Squared Error (MSE)** | Measures average squared difference between predicted & actual values. |
| **R¬≤ Score (R-Squared)** | Measures how well the model explains the variance in data. |
| **Cross-Validation Score** | Checks how well the function generalizes to unseen data. |

**Lower MSE** & **Higher R¬≤ Score** = **Better Function Learning!**

---

## Conclusion
Machine learning is all about learning functions that map inputs to outputs. The more accurately this function is learned (with minimal error), the better the model will make predictions. Different algorithms approach this task in varied ways based on the assumptions they make about the function.

---

# 5. Bias-Variance Tradeoff

The **Bias-Variance Tradeoff** is a cornerstone concept in machine learning that addresses the challenge of balancing two sources of error bias and variance to ensure a model generalizes well to unseen data. This tradeoff is critical when designing models, as it influences their predictive performance. 

## What is the Bias-Variance Tradeoff?

In machine learning, a model's error when predicting on new data can be broken down into three components:

1. **Bias**: The error due to overly simplistic assumptions in the model. High bias occurs when a model is too basic to capture the underlying patterns in the data, leading to **underfitting**. For instance, using a linear model to fit a nonlinear relationship introduces high bias.

2. **Variance**: The error due to sensitivity to small fluctuations in the training data. High variance arises when a model is too complex and fits the noise in the training data, resulting in **overfitting**. Such models perform well on training data but poorly on new data.

3. **Irreducible Error**: The inherent noise in the data that cannot be eliminated, regardless of the model.

The **total error** of a model can be expressed as:

```math
   Total Error = Bias¬≤ + Variance + Noise
```

The tradeoff arises because decreasing bias (e.g., by increasing model complexity) typically increases variance, and vice versa. The goal is to find an optimal model complexity that minimizes the total error, striking a balance between underfitting and overfitting.

## Formal Decomposition

Suppose we aim to approximate a true function \( f(x) \) with a model \( \hat{f}(x) \), trained on a dataset with noise \( y = f(x) + \epsilon \), where \( \epsilon \) is random noise with mean 0 and variance \( \sigma^2 \). The expected squared error at a point \( x \) is:

\[ E[(y - \hat{f}(x))^2] = (E[\hat{f}(x)] - f(x))^2 + E[(\hat{f}(x) - E[\hat{f}(x)])^2] + \sigma^2 \]

- **Bias**: \( E[\hat{f}(x)] - f(x) \), the difference between the expected prediction and the true value.
- **Variance**: \( E[(\hat{f}(x) - E[\hat{f}(x)])^2] \), the variability of the model‚Äôs predictions across different training sets.
- **Irreducible Error**: \( \sigma^2 \), the noise variance.

The tradeoff is managed by tuning model complexity to minimize \(Bias¬≤ + Variance\).

## **Breaking Down Prediction Errors**
The total prediction error of a model can be split into three parts:
1. **Bias¬≤**: Error from oversimplified assumptions (squared to ensure it‚Äôs positive).
2. **Variance**: Error from sensitivity to training data changes.
3. **Irreducible Error**: Noise that‚Äôs always present.

## **The Bias-Variance Tradeoff Explained**
The tradeoff is about finding the "sweet spot" in model complexity:
- **Increase Complexity**: Bias decreases (better fit to patterns), but variance increases (more sensitivity to noise).
- **Decrease Complexity**: Variance decreases (more stable predictions), but bias increases (misses patterns).

### **Visualizing the Tradeoff**
Imagine a dartboard:
- **High Bias**: Darts consistently hit far from the bullseye (underfitting).
- **High Variance**: Darts are scattered all over the board (overfitting).
- **Balanced Model**: Darts cluster near the bullseye (good generalization).

### **Bias-Variance Scenarios**
| **Bias** | **Variance** | **Result**           | **Accuracy** |
|----------|--------------|----------------------|--------------|
| Low      | Low          | Ideal model          | High ‚úÖ       |
| Low      | High         | Overfitting          | Low ‚ùå        |
| High     | Low          | Underfitting         | Low ‚ùå        |
| High     | High         | Worst case           | Very Low ‚ùå   |

## Examples Illustrating the Tradeoff

### Example 1: Linear Regression on Nonlinear Data
Imagine data generated by \( y = x^2 + \epsilon \), where \( \epsilon \) is noise. Fitting a linear model \( y = mx + b \) results in high bias because it cannot capture the quadratic relationship, leading to underfitting. Conversely, fitting a high-degree polynomial (e.g., degree 15) might perfectly match the training data, including noise, but its predictions vary widely with different training samples, indicating high variance and overfitting.

### Example 2: Decision Trees
A shallow decision tree (e.g., depth 2) has high bias, making broad assumptions that miss intricate patterns. A deep tree (e.g., depth 20) has high variance, fitting the training data too closely, including noise, and failing to generalize.

In both cases, the optimal model complexity‚Äîe.g., a polynomial of degree 2 or a tree of moderate depth‚Äîbalances bias and variance.

## Tools and Methods to Manage the Tradeoff

Several techniques help navigate the bias-variance tradeoff:

1. **Cross-Validation**: Splits data into training and validation sets multiple times to estimate generalization error, aiding in model complexity selection.
2. **Regularization**: Adds a penalty to model complexity (e.g., Ridge or Lasso regression), reducing variance by introducing controlled bias.
3. **Ensemble Methods**:
   - **Bagging** (e.g., Random Forests): Reduces variance by averaging predictions from models trained on different data subsets.
   - **Boosting** (e.g., Gradient Boosting): Reduces bias by iteratively correcting errors.
4. **Model Selection**: Choosing an appropriate algorithm or hyperparameters (e.g., polynomial degree, tree depth) based on validation performance.
5. **Data Augmentation**: Increasing training data size can reduce variance by making the model less sensitive to specific samples.

## A One-Stop Python Solution

Let‚Äôs implement a demonstration using polynomial regression to visualize the bias-variance tradeoff. We‚Äôll generate synthetic data from \( y = \sin(x) + \epsilon \), fit polynomials of varying degrees, and compute bias, variance, and total error.

### Complete Python Code

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline

# Define the true function
def true_function(x):
    return np.sin(x)

# Generate noisy training data
def generate_data(n_samples=20, noise=0.1):
    x = np.random.uniform(0, 2*np.pi, n_samples)
    y = true_function(x) + np.random.normal(0, noise, n_samples)
    return x, y

# Parameters
n_train_sets = 200  # Number of training sets to simulate
n_samples = 20      # Samples per training set
noise = 0.1         # Noise level
degrees = range(1, 16)  # Polynomial degrees to test
x_test = np.linspace(0, 2*np.pi, 100)  # Fixed test set
y_test_true = true_function(x_test)    # True function values

# Compute bias, variance, and total error for each degree
bias_squared = []
variance = []
total_error = []

for degree in degrees:
    predictions = []
    for _ in range(n_train_sets):
        x_train, y_train = generate_data(n_samples, noise)
        # Fit polynomial regression model
        model = make_pipeline(PolynomialFeatures(degree), LinearRegression())
        model.fit(x_train[:, np.newaxis], y_train)
        y_pred = model.predict(x_test[:, np.newaxis])
        predictions.append(y_pred)
    
    predictions = np.array(predictions)  # Shape: (n_train_sets, n_test_points)
    avg_pred = np.mean(predictions, axis=0)  # Average prediction
    bias = avg_pred - y_test_true            # Bias at each test point
    bias_squared_degree = np.mean(bias**2)   # Average squared bias
    variance_degree = np.mean(np.var(predictions, axis=0))  # Average variance
    total_error_degree = np.mean((predictions - y_test_true)**2)  # Average squared error
    
    bias_squared.append(bias_squared_degree)
    variance.append(variance_degree)
    total_error.append(total_error_degree)

# Plot Bias^2, Variance, and Total Error
plt.figure(figsize=(10, 6))
plt.plot(degrees, bias_squared, label='Bias^2')
plt.plot(degrees, variance, label='Variance')
plt.plot(degrees, total_error, label='Total Error')
plt.xlabel('Polynomial Degree')
plt.ylabel('Error')
plt.legend()
plt.title('Bias-Variance Tradeoff')
plt.show()

# Visualize fitted models for selected degrees
degrees_to_plot = [1, 3, 15]
plt.figure(figsize=(15, 5))
for i, degree in enumerate(degrees_to_plot):
    plt.subplot(1, 3, i+1)
    plt.plot(x_test, y_test_true, label='True function', color='black')
    for _ in range(10):
        x_train, y_train = generate_data(n_samples, noise)
        model = make_pipeline(PolynomialFeatures(degree), LinearRegression())
        model.fit(x_train[:, np.newaxis], y_train)
        y_pred = model.predict(x_test[:, np.newaxis])
        plt.plot(x_test, y_pred, color='blue', alpha=0.2)
    plt.title(f'Degree {degree}')
    plt.legend()
plt.show()
```

### Explanation of the Code

1. **Data Generation**: We simulate data from \( y = \sin(x) + \epsilon \), where \( \epsilon \sim N(0, 0.1) \), over the interval \( [0, 2\pi] \).
2. **Model Fitting**: For each polynomial degree (1 to 15), we train 200 models on different training sets and predict on a fixed test set.
3. **Metrics Calculation**:
   - **Bias^2**: Mean squared difference between the average prediction and the true function.
   - **Variance**: Mean variance of predictions across models.
   - **Total Error**: Mean squared error between predictions and the true function (approximates \( \text{Bias}^2 + \text{Variance} \)).
4. **Visualization**:
   - The first plot shows how \( \text{Bias}^2 \) decreases, \( \text{Variance} \) increases, and \( \text{Total Error} \) forms a U-shape with increasing degree.
   - The second plot visualizes fitted curves for degrees 1, 3, and 15, illustrating high bias (degree 1), balanced fit (degree 3), and high variance (degree 15).

### Expected Output
- **Bias-Variance Plot**: Bias^2 starts high and drops, variance starts low and rises, and total error has a minimum at an intermediate degree (e.g., 3‚Äì5).
- **Fitted Curves**: Degree 1 fits are straight lines (high bias), degree 3 fits approximate the sine wave, and degree 15 fits vary wildly (high variance).

## Conclusion

The Bias-Variance Tradeoff emphasizes the need to balance model simplicity and flexibility. Too simple a model underfits with high bias; too complex a model overfits with high variance. 

---


# 6. Underfitting and Overfitting

---

## **Key Terms to Understand**

To get underfitting and overfitting, you need to know these basics:

- **Noise**: Random or useless data that confuses the model. It‚Äôs always there, but a good model ignores it.
- **Bias**: Errors from a model being too simple. High bias causes underfitting.
- **Variance**: Errors from a model being too sensitive to the training data. High variance causes overfitting.

### **The Goldilocks Zone: Balanced Model**
A good model should:
1. **Learn patterns** from training data.
2. **Generalize well** to unseen data meaning:
    - **Good training performance** ‚úÖ
    - **Good test performance** ‚úÖ
    - **Balanced bias and variance** ‚úÖ

---

## Understanding Underfitting and Overfitting

In machine learning, the goal is to build a model that generalizes well to unseen data. However, two common pitfalls can prevent this: **underfitting** and **overfitting**.

### **Underfitting**
- **Definition:** Underfitting occurs when a model is too simple to capture the underlying patterns in the data. It fails to learn the relationships effectively, leading to poor performance on both the training data and unseen test data.
- **Characteristics:**
  - High error on training data (poor fit).
  - High error on test data (poor generalization).
- **Cause:** The model lacks sufficient complexity (e.g., a linear model applied to nonlinear data) or is undertrained.

### **Overfitting**
- **Definition:** Overfitting happens when a model is too complex and learns not only the underlying patterns but also the noise or random fluctuations in the training data. While it performs well on the training set, it fails to generalize to new data.
- **Characteristics:**
  - Low error on training data (excellent fit).
  - High error on test data (poor generalization).
- **Cause:** Excessive model complexity (e.g., a high-degree polynomial) or insufficient regularization.

---

## Examples

### **Underfitting Example**
Imagine trying to fit a quadratic relationship (e.g., \( y = x^2 \)) using a simple linear regression model (e.g., \( y = mx + b \)). The straight line cannot capture the curve, resulting in a poor fit to both training and test data.

### **Overfitting Example**
Now consider fitting a simple linear relationship (e.g., \( y = 2x + 1 \)) with a 15th-degree polynomial. The model will wiggle excessively to match every training point, including noise, leading to a great fit on training data but poor performance on unseen data.

## **Example: Studying for a Math Exam**

Imagine three students preparing for a math test. Their approaches show how underfitting, overfitting, and a good fit work:

| **Student**   | **Study Method**                           | **Exam Result**                         | **ML Match**   |
|---------------|--------------------------------------------|-----------------------------------------|----------------|
| Student 1     | Only learned addition                      | Failed most questions                   | Underfitting üìâ |
| Student 2     | Memorized one textbook word-for-word       | Failed new question types               | Overfitting üìâ |
| Student 3     | Studied all topics, practiced widely       | Did well on all questions               | Good Fit ‚úÖ    |

- **Student 1 (Underfitting)**: Too little effort, missed the big picture.
- **Student 2 (Overfitting)**: Too much focus on one thing, no flexibility.
- **Student 3 (Good Fit)**: Balanced effort, ready for anything.

This is like machine learning:
- **Underfitting**: The model doesn‚Äôt learn enough.
- **Overfitting**: The model learns too much, including useless details.
- **Good Fit**: The model learns just what it needs to succeed.

---

## Tools and Methods to Address Underfitting and Overfitting

To detect and mitigate these issues, we use several techniques:

1. **Model Evaluation Metrics**
   - Use metrics like **Mean Squared Error (MSE)** or **R-squared** to quantify performance on training and test sets.
   - High MSE on both indicates underfitting; low training MSE but high test MSE suggests overfitting.

2. **Cross-Validation**
   - Techniques like **k-fold cross-validation** assess how well the model generalizes to unseen data by splitting the dataset into multiple training and validation subsets.

3. **Regularization**
   - Methods like **L1 (Lasso)** and **L2 (Ridge)** regularization add penalties to the model‚Äôs coefficients, reducing complexity and preventing overfitting.

4. **Learning Curves**
   - Plot training and validation errors against the number of training examples to visualize underfitting (high errors converging) or overfitting (large gap between training and validation errors).

5. **Model Selection**
   - Choose an appropriate model complexity (e.g., polynomial degree) based on the data‚Äôs underlying patterns.

---

## Python Code Demonstration

Let‚Äôs implement these concepts with a synthetic dataset, showing examples of underfitting, overfitting, and an optimal model. We‚Äôll use Python libraries like `scikit-learn` and `matplotlib`.

### Code

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, learning_curve
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline
from sklearn.metrics import mean_squared_error

# Generate synthetic data (sinusoidal with noise)
np.random.seed(0)
X = np.sort(5 * np.random.rand(80, 1), axis=0)
y = np.sin(X).ravel() + np.random.normal(0, 0.1, X.shape[0])

# Split data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

# Function to plot learning curves
def plot_learning_curve(estimator, title, X, y, cv=None, train_sizes=np.linspace(0.1, 1.0, 5)):
    plt.figure()
    plt.title(title)
    plt.xlabel("Training examples")
    plt.ylabel("Score")
    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, train_sizes=train_sizes)
    train_scores_mean = np.mean(train_scores, axis=1)
    train_scores_std = np.std(train_scores, axis=1)
    test_scores_mean = np.mean(test_scores, axis=1)
    test_scores_std = np.std(test_scores, axis=1)
    plt.grid()
    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color="r")
    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color="g")
    plt.plot(train_sizes, train_scores_mean, 'o-', color="r", label="Training score")
    plt.plot(train_sizes, test_scores_mean, 'o-', color="g", label="Cross-validation score")
    plt.legend(loc="best")
    return plt

# 1. Underfitting: Linear Regression
linear_model = LinearRegression()
linear_model.fit(X_train, y_train)
y_pred_train_linear = linear_model.predict(X_train)
y_pred_test_linear = linear_model.predict(X_test)
print("Underfitting - Linear Regression")
print("Train MSE:", mean_squared_error(y_train, y_pred_train_linear))
print("Test MSE:", mean_squared_error(y_test, y_pred_test_linear))

# 2. Overfitting: High-degree polynomial regression (degree=15)
degree = 15
poly_model = make_pipeline(PolynomialFeatures(degree), LinearRegression())
poly_model.fit(X_train, y_train)
y_pred_train_poly = poly_model.predict(X_train)
y_pred_test_poly = poly_model.predict(X_test)
print("\nOverfitting - Polynomial Regression (degree=15)")
print("Train MSE:", mean_squared_error(y_train, y_pred_train_poly))
print("Test MSE:", mean_squared_error(y_test, y_pred_test_poly))

# 3. Optimal Model: Polynomial regression (degree=2) with Ridge regularization
optimal_model = make_pipeline(PolynomialFeatures(2), Ridge(alpha=0.1))
optimal_model.fit(X_train, y_train)
y_pred_train_optimal = optimal_model.predict(X_train)
y_pred_test_optimal = optimal_model.predict(X_test)
print("\nOptimal Model - Polynomial Regression (degree=2) with Ridge")
print("Train MSE:", mean_squared_error(y_train, y_pred_train_optimal))
print("Test MSE:", mean_squared_error(y_test, y_pred_test_optimal))

# Plotting the results
plt.figure(figsize=(14, 4))

# Underfitting plot
plt.subplot(1, 3, 1)
plt.scatter(X_train, y_train, color='blue', label='Train data')
plt.scatter(X_test, y_test, color='green', label='Test data')
plt.plot(X, linear_model.predict(X), color='red', label='Linear model')
plt.title('Underfitting - Linear Regression')
plt.legend()

# Overfitting plot
plt.subplot(1, 3, 2)
plt.scatter(X_train, y_train, color='blue', label='Train data')
plt.scatter(X_test, y_test, color='green', label='Test data')
X_plot = np.linspace(0, 5, 100).reshape(-1, 1)
plt.plot(X_plot, poly_model.predict(X_plot), color='red', label='Polynomial (degree=15)')
plt.title('Overfitting - Polynomial Regression')
plt.legend()

# Optimal model plot
plt.subplot(1, 3, 3)
plt.scatter(X_train, y_train, color='blue', label='Train data')
plt.scatter(X_test, y_test, color='green', label='Test data')
plt.plot(X_plot, optimal_model.predict(X_plot), color='red', label='Optimal (degree=2)')
plt.title('Optimal Model')
plt.legend()

plt.show()

# Learning curves for the optimal model
plot_learning_curve(optimal_model, "Learning Curves (Optimal Model)", X, y, cv=5)
plt.show()
```

---

## Explanation of the Code

### **Dataset**
- We generate a synthetic dataset where \( y = \sin(x) + \text{noise} \), simulating a nonlinear pattern with some randomness.

### **Models**
1. **Underfitting: Linear Regression**
   - A straight line is fitted to the sinusoidal data.
   - **Result:** High MSE on both training (~0.24) and test (~0.23) sets, indicating the model is too simple to capture the pattern.

2. **Overfitting: Polynomial Regression (degree=15)**
   - A 15th-degree polynomial fits the training data almost perfectly, including noise.
   - **Result:** Very low training MSE (~0.01) but high test MSE (~0.25), showing poor generalization.

3. **Optimal Model: Polynomial Regression (degree=2) with Ridge**
   - A 2nd-degree polynomial with Ridge regularization balances complexity and generalization.
   - **Result:** Reasonable MSE on training (~0.05) and test (~0.06), indicating a good fit.

### **Visualizations**
- **Plots:** Three subplots show the data and fitted models for underfitting, overfitting, and the optimal case.
- **Learning Curves:** For the optimal model, training and validation scores converge, confirming good generalization.

---

## Summary

- **Underfitting:** Too simple (e.g., linear model on nonlinear data). Fix by increasing model complexity or training time.
- **Overfitting:** Too complex (e.g., high-degree polynomial). Fix by reducing complexity, adding regularization, or collecting more data.
- **Tools:** MSE, cross-validation, regularization, learning curves, and model selection help diagnose and resolve these issues.

---