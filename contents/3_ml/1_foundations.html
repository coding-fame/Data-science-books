
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>ML Foundational &#8212; Data Science Books</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-dropdown.css?v=995e94df" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-bootstrap.min.css?v=21c0b90a" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=d567e03f" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'contents/3_ml/1_foundations';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="2ï¸âƒ£ Data Handling" href="2_data_preparation.html" />
    <link rel="prev" title="What is Feature Engineering?" href="../2_pandas/5_feature_engineering.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
  
    <p class="title logo__title">Data Science Books</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Machine Learning
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Part I â€” Foundations</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../0_maths/0_essential.html">Essential Mathematics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../0_maths/4_linear_algebra.html">Linear Algebra</a></li>







<li class="toctree-l1"><a class="reference internal" href="../0_maths/2_probability.html">Probability Theory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../0_maths/1_descriptive.html">Descriptive Statistics</a></li>








<li class="toctree-l1"><a class="reference internal" href="../0_maths/3_inferential.html">Inferential Statistics</a></li>



<li class="toctree-l1"><a class="reference internal" href="../0_maths/5_calculus.html">Calculus</a></li>







<li class="toctree-l1"><a class="reference internal" href="../0_maths/6_regression_analysis.html">Explanatory and Response Variables</a></li>


<li class="toctree-l1"><a class="reference internal" href="../1_python/1_basics.html">Python Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../1_python/2_advanced.html">Advanced Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../1_python/3_data_structures.html">Data Structures</a></li>





<li class="toctree-l1"><a class="reference internal" href="../1_python/4_modules_packages.html">Modules &amp; Packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../1_python/5_functions.html">Functions &amp; Modular Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../1_python/6_oop.html">Object-Oriented Programming</a></li>





<li class="toctree-l1"><a class="reference internal" href="../1_python/8_exceptions.html">Exception Management</a></li>
<li class="toctree-l1"><a class="reference internal" href="../1_python/9_regex.html">Regular Expressions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2_numpy/1_numpy.html">NumPy (<strong>Numerical Python</strong>)</a></li>



<li class="toctree-l1"><a class="reference internal" href="../2_pandas/1_series.html">Pandas Series</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2_pandas/2_dataframes.html">Pandas DataFrame</a></li>
















<li class="toctree-l1"><a class="reference internal" href="../2_pandas/3_visualization.html"><strong>What is Data Visualization in Data Science?</strong></a></li>


<li class="toctree-l1"><a class="reference internal" href="../2_pandas/4_eda.html">Exploratory Data Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2_pandas/5_feature_engineering.html"><strong>What is Feature Engineering?</strong></a></li>


</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part II â€” Classical Machine Learning</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">ML Foundational</a></li>





<li class="toctree-l1"><a class="reference internal" href="2_data_preparation.html">2ï¸âƒ£ Data Handling</a></li>





<li class="toctree-l1"><a class="reference internal" href="2_train_test_split.html">Trainâ€“Test Split</a></li>
<li class="toctree-l1"><a class="reference internal" href="5_model_evaluation.html">4ï¸âƒ£ Model Evaluation</a></li>




<li class="toctree-l1"><a class="reference internal" href="11_supervised_learning.html"><strong>Supervised Learning</strong></a></li>



<li class="toctree-l1"><a class="reference internal" href="12_regression.html">Regression Algorithms</a></li>







<li class="toctree-l1"><a class="reference internal" href="13_classification.html">Classification Algorithms</a></li>

<li class="toctree-l1"><a class="reference internal" href="10_core_algo.html">Core ML Algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="14_decision_trees.html">Decision Trees</a></li>
<li class="toctree-l1"><a class="reference internal" href="15_ensemble_methods.html">Ensemble Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="16_svm.html">Support Vector Machine (SVM) in Detail</a></li>


<li class="toctree-l1"><a class="reference internal" href="17_knn.html">k-Nearest Neighbors</a></li>
<li class="toctree-l1"><a class="reference internal" href="18_naive_bayes.html">Naive Bayes</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part III â€” Advanced Machine Learning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="20_unsupervised_learning.html">Unsupervised Learning</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="21_clustering.html">Clustering Techniques</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="7_optimization_and_training.html">5ï¸âƒ£ Optimization &amp; Training</a></li>







<li class="toctree-l1 has-children"><a class="reference internal" href="6_ml_lifecycle.html">ML Lifecycle</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="6_training.html">Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="6_evaluation.html">Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="6_deployment.html">Deployment</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part IV â€” Deep Learning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../4_dl/dl1_Introduction.html">Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../4_dl/dl2_Neuron.html">Neuron</a></li>
<li class="toctree-l1"><a class="reference internal" href="../4_dl/dl3_Libraries.html">Deep Learning Libraries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../4_dl/dl4_Terminology.html">Terminology</a></li>
<li class="toctree-l1"><a class="reference internal" href="../4_dl/dl5_multi_layer.html">Multi-Layer Perceptron</a></li>
<li class="toctree-l1"><a class="reference internal" href="../4_dl/dl6_first_nn.html">First Neural Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../4_dl/dl7_evaluating_model.html">Model Evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../4_dl/dl8_multiclass_classification.html">Multiclass Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../4_dl/dl9_multiclass_classification_hand.html">Handwritten Digit Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../4_dl/dl10_saving_and_loading.html">Saving &amp; Loading Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../4_dl/dl11_checkpointing.html">Model Checkpointing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../4_dl/dl12_visualizing_model_training.html"><strong>Visualizing Model Training History in Deep Learning</strong></a></li>

<li class="toctree-l1"><a class="reference internal" href="../4_dl/dl13_loss_functions_activation_functions_and_optimizers.html">Loss Functions &amp; Optimizers</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part V â€” NLP</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../5_nlp/nlp1.html">NLP Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../5_nlp/nlp2.html">Text Cleaning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../5_nlp/nlp3.html">Text Normalization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../5_nlp/nlp4.html">NLP Components</a></li>
<li class="toctree-l1"><a class="reference internal" href="../5_nlp/nlp5.html">Bag of Words, TF-IDF</a></li>
<li class="toctree-l1"><a class="reference internal" href="../5_nlp/nlp6.html">Sentiment Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../5_nlp/nlp7.html">NLP with SpaCy</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part VI â€” Career &amp; MLOps</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../6_interview/self%20introduction.html">Self Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../6_interview/py.html">Python: Interview Guide</a></li>





<li class="toctree-l1"><a class="reference internal" href="../6_interview/pd.html">ğŸ“š Pandas: Interview Guide</a></li>


<li class="toctree-l1"><a class="reference internal" href="../6_interview/ml.html">Machine Learning: Interview Guide</a></li>













<li class="toctree-l1"><a class="reference internal" href="../6_interview/git.html">Git</a></li>
<li class="toctree-l1"><a class="reference internal" href="../6_interview/dvc.html">DVC</a></li>
<li class="toctree-l1"><a class="reference internal" href="../6_interview/mlflow.html">MLflow</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/coding-fame/Data-science-books" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/coding-fame/Data-science-books/edit/main/contents/3_ml/1_foundations.ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/coding-fame/Data-science-books/issues/new?title=Issue%20on%20page%20%2Fcontents/3_ml/1_foundations.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/contents/3_ml/1_foundations.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>ML Foundational</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">ML Foundational</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-machine-learning">ğŸš€ 1. Introduction to Machine Learning</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-machine-learning">ğŸ¤– What is Machine Learning?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-aspects">ğŸ” Key Aspects:</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-a-program">ğŸ–¥ï¸ What is a Program?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#features">âœ… Features:</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-an-algorithm">ğŸ“œ What is an Algorithm?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-a-machine-learning-algorithm">ğŸ¤– What is a Machine Learning Algorithm?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#difference-between-normal-machine-learning-algorithms">ğŸ”„ Difference Between Normal &amp; Machine Learning Algorithms</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-machine-learning">ğŸ“ˆ Why Machine Learning?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#major-use-cases">ğŸŒ Major Use Cases:</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#definitions-of-machine-learning">ğŸ›ï¸ Definitions of Machine Learning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#arthur-samuels-definition-1959">ğŸ”¬ Arthur Samuelâ€™s Definition (1959):</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ai-vs-ml-vs-deep-learning">ğŸ† AI vs ML vs Deep Learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#human-vs-computer-decision-making">ğŸ§  Human vs Computer Decision-Making</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#how-do-machines-think">ğŸ’¡ How Do Machines â€œThinkâ€?</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#real-world-applications-of-machine-learning">ğŸŒ Real-World Applications of Machine Learning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gmail-spam-filter">âœ‰ï¸ <strong>Gmail Spam Filter</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#banking-loan-credit-card-approval">ğŸ¦ <strong>Banking Loan/Credit Card Approval</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">ğŸ”¥ Conclusion</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#terminology">2. Terminology</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">What is Machine Learning?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-points">Key Points:</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-a-model">What is a Model?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#types-of-models">Types of Models:</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-the-model">Training the Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-does-the-model-learn">How Does the Model Learn?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-concepts">Key Concepts:</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#testing-the-model">Testing the Model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-steps">Key Steps:</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-deployment">Model Deployment</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-a-smart-application">What is a Smart Application?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#comparison">Comparison:</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#accuracy-testing">Accuracy Testing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Key Aspects:</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-a-function">3. Learning a Function</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-function-learning-in-machine-learning">Understanding Function Learning in Machine Learning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-learning-a-function">What is Learning a Function?</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#mathematical-representation">Mathematical Representation:</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#error-inclusion">Error Inclusion:</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-is-learning-a-function-important">Why is Learning a Function Important?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">Key Points:</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#machine-learning-algorithms">Machine Learning Algorithms</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">Key Aspects:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#types-of-function-assumptions">Types of Function Assumptions</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#real-world-analogy-predicting-house-prices">Real-World Analogy: Predicting House Prices</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#input-variables-x">Input Variables (X):</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#output-variable-y">Output Variable (y):</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interactive-code-example">Interactive Code Example</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interview-prep-common-questions-concepts">Interview Prep: Common Questions &amp; Concepts</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-a-target-function-in-ml">1. What is a target function in ML?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-does-the-error-exist-in-function-learning">2. Why does the error exist in function learning?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-the-difference-between-linear-and-nonlinear-function-assumptions">3. What is the difference between linear and nonlinear function assumptions?</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#success-metrics-how-to-evaluate-a-learned-function">Success Metrics: How to Evaluate a Learned Function?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">Conclusion</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#bias-variance-tradeoff">5. Bias-Variance Tradeoff</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-the-bias-variance-tradeoff">What is the Bias-Variance Tradeoff?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#formal-decomposition">Formal Decomposition</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#breaking-down-prediction-errors"><strong>Breaking Down Prediction Errors</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-bias-variance-tradeoff-explained"><strong>The Bias-Variance Tradeoff Explained</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizing-the-tradeoff"><strong>Visualizing the Tradeoff</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bias-variance-scenarios"><strong>Bias-Variance Scenarios</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#examples-illustrating-the-tradeoff">Examples Illustrating the Tradeoff</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-1-linear-regression-on-nonlinear-data">Example 1: Linear Regression on Nonlinear Data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-2-decision-trees">Example 2: Decision Trees</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tools-and-methods-to-manage-the-tradeoff">Tools and Methods to Manage the Tradeoff</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-one-stop-python-solution">A One-Stop Python Solution</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#complete-python-code">Complete Python Code</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#explanation-of-the-code">Explanation of the Code</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#expected-output">Expected Output</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">Conclusion</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#underfitting-and-overfitting">6. Underfitting and Overfitting</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-terms-to-understand"><strong>Key Terms to Understand</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-goldilocks-zone-balanced-model"><strong>The Goldilocks Zone: Balanced Model</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-underfitting-and-overfitting">Understanding Underfitting and Overfitting</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#underfitting"><strong>Underfitting</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#overfitting"><strong>Overfitting</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#examples">Examples</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#underfitting-example"><strong>Underfitting Example</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#overfitting-example"><strong>Overfitting Example</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-studying-for-a-math-exam"><strong>Example: Studying for a Math Exam</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tools-and-methods-to-address-underfitting-and-overfitting">Tools and Methods to Address Underfitting and Overfitting</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#python-code-demonstration">Python Code Demonstration</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#code">Code</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">Explanation of the Code</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset"><strong>Dataset</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#models"><strong>Models</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizations"><strong>Visualizations</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a></li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="ml-foundational">
<h1>ML Foundational<a class="headerlink" href="#ml-foundational" title="Link to this heading">#</a></h1>
</section>
<hr class="docutils" />
<section id="introduction-to-machine-learning">
<h1>ğŸš€ 1. Introduction to Machine Learning<a class="headerlink" href="#introduction-to-machine-learning" title="Link to this heading">#</a></h1>
<section id="what-is-machine-learning">
<h2>ğŸ¤– What is Machine Learning?<a class="headerlink" href="#what-is-machine-learning" title="Link to this heading">#</a></h2>
<p>Machine learning is a technique that enables computers to learn automatically from past data without explicit programming.</p>
<ul class="simple">
<li><p><strong>Purpose</strong>: Machine learning helps make predictions based on data by identifying patterns and relationships in it.</p></li>
<li><p><strong>Example</strong>: Predicting future values based on past data.</p></li>
</ul>
<section id="key-aspects">
<h3>ğŸ” Key Aspects:<a class="headerlink" href="#key-aspects" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>It is an approach to train models.</p></li>
<li><p>It helps predict future values based on past data.</p></li>
</ul>
<blockquote>
<div><p>ğŸ§  <em>Analogy:</em> Think of ML like a student learning from past exam papers to predict the types of questions in future exams.</p>
</div></blockquote>
</section>
</section>
<hr class="docutils" />
<section id="what-is-a-program">
<h2>ğŸ–¥ï¸ What is a Program?<a class="headerlink" href="#what-is-a-program" title="Link to this heading">#</a></h2>
<p>A program is a group of instructions that a computer executes to perform a specific task.</p>
<section id="features">
<h3>âœ… Features:<a class="headerlink" href="#features" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Good for simple, well-defined tasks.</p></li>
<li><p>Cannot adapt or improve performance over time.</p></li>
</ul>
<blockquote>
<div><p>ğŸ“Œ <em>Example:</em> A calculator program that adds numbers based on predefined logic.</p>
</div></blockquote>
</section>
</section>
<hr class="docutils" />
<section id="what-is-an-algorithm">
<h2>ğŸ“œ What is an Algorithm?<a class="headerlink" href="#what-is-an-algorithm" title="Link to this heading">#</a></h2>
<p>An algorithm is a set of instructions to perform a task.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Formula</p></th>
<th class="head"><p>Explanation</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Input + Logic = Output</p></td>
<td><p>A program processes input using logic to produce an output.</p></td>
</tr>
<tr class="row-odd"><td><p>Data + Program = Result</p></td>
<td><p>When applied to data, a program generates results.</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<hr class="docutils" />
<section id="what-is-a-machine-learning-algorithm">
<h2>ğŸ¤– What is a Machine Learning Algorithm?<a class="headerlink" href="#what-is-a-machine-learning-algorithm" title="Link to this heading">#</a></h2>
<p>A Machine Learning (ML) algorithm is a special type of program that learns from data without being explicitly programmed.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Formula</p></th>
<th class="head"><p>Explanation</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Data + Result = Program (Model)</p></td>
<td><p>The model adjusts itself based on the provided data and results.</p></td>
</tr>
</tbody>
</table>
</div>
<section id="difference-between-normal-machine-learning-algorithms">
<h3>ğŸ”„ Difference Between Normal &amp; Machine Learning Algorithms<a class="headerlink" href="#difference-between-normal-machine-learning-algorithms" title="Link to this heading">#</a></h3>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Feature</p></th>
<th class="head"><p>Normal Algorithm</p></th>
<th class="head"><p>Machine Learning Algorithm</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Learning Ability</p></td>
<td><p>Cannot learn</p></td>
<td><p>Learns patterns from data</p></td>
</tr>
<tr class="row-odd"><td><p>Adaptability</p></td>
<td><p>Fixed rules</p></td>
<td><p>Adjusts based on input</p></td>
</tr>
</tbody>
</table>
</div>
</section>
</section>
<hr class="docutils" />
<section id="why-machine-learning">
<h2>ğŸ“ˆ Why Machine Learning?<a class="headerlink" href="#why-machine-learning" title="Link to this heading">#</a></h2>
<p>With the massive increase in data generation, ML helps extract valuable insights and make predictions.</p>
<section id="major-use-cases">
<h3>ğŸŒ Major Use Cases:<a class="headerlink" href="#major-use-cases" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Creating models</strong> to solve complex problems.</p></li>
<li><p><strong>Extracting deep insights</strong> from large datasets.</p></li>
<li><p><strong>Predicting future trends</strong> based on historical data.</p></li>
</ul>
<blockquote>
<div><p>ğŸš€ <em>Future Impact:</em> Machine learning is poised to be a central element in all industries, shaping the future of technology.</p>
</div></blockquote>
</section>
</section>
<hr class="docutils" />
<section id="definitions-of-machine-learning">
<h2>ğŸ›ï¸ Definitions of Machine Learning<a class="headerlink" href="#definitions-of-machine-learning" title="Link to this heading">#</a></h2>
<section id="arthur-samuels-definition-1959">
<h3>ğŸ”¬ Arthur Samuelâ€™s Definition (1959):<a class="headerlink" href="#arthur-samuels-definition-1959" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Enables machines to learn from data.</p></li>
<li><p>Improves performance based on experiences.</p></li>
<li><p>Makes predictions without explicit programming.</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="ai-vs-ml-vs-deep-learning">
<h2>ğŸ† AI vs ML vs Deep Learning<a class="headerlink" href="#ai-vs-ml-vs-deep-learning" title="Link to this heading">#</a></h2>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Concept</p></th>
<th class="head"><p>Definition</p></th>
<th class="head"><p>Example</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Artificial Intelligence (AI)</strong></p></td>
<td><p>The ability of computers to mimic human thinking.</p></td>
<td><p>Sophia, an advanced AI model.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Machine Learning (ML)</strong></p></td>
<td><p>A subset of AI that allows systems to learn from data.</p></td>
<td><p>Netflix recommending shows.</p></td>
</tr>
<tr class="row-even"><td><p><strong>Deep Learning (DL)</strong></p></td>
<td><p>A subset of ML that uses neural networks to mimic human thought.</p></td>
<td><p>Self-driving cars.</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<hr class="docutils" />
<section id="human-vs-computer-decision-making">
<h2>ğŸ§  Human vs Computer Decision-Making<a class="headerlink" href="#human-vs-computer-decision-making" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><strong>Humans</strong>: make decisions based on experience.</p></li>
<li><p><strong>Computers</strong>: Use data to create models and make predictions.</p></li>
</ul>
<section id="how-do-machines-think">
<h3>ğŸ’¡ How Do Machines â€œThinkâ€?<a class="headerlink" href="#how-do-machines-think" title="Link to this heading">#</a></h3>
<p>The goal is to make computers think like humans using a three-step process:</p>
<ol class="arabic simple">
<li><p><strong>Remember:</strong> Analyze massive datasets.</p></li>
<li><p><strong>Formulate:</strong> Apply rules and patterns.</p></li>
<li><p><strong>Predict:</strong> Use these patterns to make predictions.</p></li>
</ol>
</section>
</section>
<hr class="docutils" />
<section id="real-world-applications-of-machine-learning">
<h2>ğŸŒ Real-World Applications of Machine Learning<a class="headerlink" href="#real-world-applications-of-machine-learning" title="Link to this heading">#</a></h2>
<section id="gmail-spam-filter">
<h3>âœ‰ï¸ <strong>Gmail Spam Filter</strong><a class="headerlink" href="#gmail-spam-filter" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>The ML algorithm learns from past emails.</p></li>
<li><p>It creates models based on spam vs. non-spam patterns.</p></li>
<li><p>It applies these models to new emails to filter spam.</p></li>
</ol>
</section>
<section id="banking-loan-credit-card-approval">
<h3>ğŸ¦ <strong>Banking Loan/Credit Card Approval</strong><a class="headerlink" href="#banking-loan-credit-card-approval" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>A customer applies for a loan, submitting documents (data).</p></li>
<li><p>The ML algorithm analyzes income, spending, and credit history.</p></li>
<li><p>It predicts whether the loan should be approved.</p></li>
</ol>
</section>
</section>
<hr class="docutils" />
<section id="conclusion">
<h2>ğŸ”¥ Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading">#</a></h2>
<p>Machine learning is transforming industries by automating tasks, making predictions, and extracting valuable insights from data. Its applications will continue to grow, revolutionizing the way we work and interact with technology.</p>
<blockquote>
<div><p>â€œMachine Learning isnâ€™t the future; itâ€™s the present!â€ ğŸš€</p>
</div></blockquote>
</section>
</section>
<hr class="docutils" />
<section id="terminology">
<h1>2. Terminology<a class="headerlink" href="#terminology" title="Link to this heading">#</a></h1>
<hr class="docutils" />
<section id="id1">
<h2>What is Machine Learning?<a class="headerlink" href="#id1" title="Link to this heading">#</a></h2>
<p>Machine Learning (ML) is a technique that enables computers to learn automatically from past data and make predictions or decisions without being explicitly programmed.</p>
<section id="key-points">
<h3>Key Points:<a class="headerlink" href="#key-points" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Purpose</strong>: Train models to recognize patterns and make future predictions.</p></li>
<li><p><strong>Applications</strong>: Used in various fields like healthcare, finance, and technology.</p></li>
<li><p><strong>Example</strong>: Predicting house prices based on historical data.</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="what-is-a-model">
<h2>What is a Model?<a class="headerlink" href="#what-is-a-model" title="Link to this heading">#</a></h2>
<p>A <strong>model</strong> is a simplified representation of reality, created to solve a specific problem.</p>
<section id="types-of-models">
<h3>Types of Models:<a class="headerlink" href="#types-of-models" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p><strong>Piece of Code or Program</strong>: A program that processes input data and produces output.</p></li>
<li><p><strong>Mathematical Formula</strong>: A set of equations that represent relationships between variables.</p></li>
<li><p><strong>Combination of Program + Mathematical Formula</strong>: A hybrid approach that uses both code and equations.</p></li>
</ol>
<p><strong>Example</strong>: A model that predicts weather based on temperature, humidity, and wind speed.</p>
</section>
</section>
<hr class="docutils" />
<section id="training-the-model">
<h2>Training the Model<a class="headerlink" href="#training-the-model" title="Link to this heading">#</a></h2>
<p>Training a model involves using data to teach it to recognize patterns and make predictions.</p>
<ul class="simple">
<li><p>ğŸ“Œ A model <strong>must be trained</strong> using data.</p></li>
<li><p>ğŸ“ Training helps the model <strong>learn patterns</strong> from the data.</p></li>
<li><p>ğŸ”„ Before training, the model has <strong>no knowledge</strong> about the patterns.</p></li>
<li><p>ğŸ¯ After training, the model understands <strong>patterns</strong> and can make predictions.</p></li>
</ul>
<p><strong>Analogy</strong>:</p>
<blockquote>
<div><p><em>Training a model is like teaching a student to recognize different animal species based on labeled examples.</em></p>
</div></blockquote>
</section>
<hr class="docutils" />
<section id="how-does-the-model-learn">
<h2>How Does the Model Learn?<a class="headerlink" href="#how-does-the-model-learn" title="Link to this heading">#</a></h2>
<p>A model learns by identifying <strong>patterns</strong> in the data.</p>
<section id="key-concepts">
<h3>Key Concepts:<a class="headerlink" href="#key-concepts" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Patterns</strong>: Represent knowledge gained during training.</p></li>
<li><p><strong>Generalization</strong>: The ability of the model to perform well on unseen data.</p></li>
<li><p><strong>Feature Extraction</strong>: Identifying important attributes in the data.</p></li>
</ul>
<p><strong>Example</strong>:</p>
<ul class="simple">
<li><p>A model trained on images of cats and dogs learns to differentiate between them based on features like shape, size, and color.</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="testing-the-model">
<h2>Testing the Model<a class="headerlink" href="#testing-the-model" title="Link to this heading">#</a></h2>
<p>After training, the model must be tested to evaluate its performance.</p>
<section id="key-steps">
<h3>Key Steps:<a class="headerlink" href="#key-steps" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p><strong>Test Data</strong>: Use new, unseen data to evaluate the model.</p></li>
<li><p><strong>Prediction</strong>: Compare the modelâ€™s predictions with actual results.</p></li>
<li><p><strong>Accuracy</strong>: Measure how well the model performs.</p></li>
</ol>
<p><strong>Outcome</strong>:</p>
<ul class="simple">
<li><p><strong>High Accuracy</strong>: The model is ready for deployment.</p></li>
<li><p><strong>Low Accuracy</strong>: The model needs improvement (e.g., more data, better features).</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="model-deployment">
<h2>Model Deployment<a class="headerlink" href="#model-deployment" title="Link to this heading">#</a></h2>
<p>Once a model achieves good accuracy, it is deployed for real-world use.</p>
<ul class="simple">
<li><p>ğŸ“Œ The trained model is integrated into an application.</p></li>
<li><p>ğŸ¯ The model <strong>makes predictions</strong> and <strong>takes decisions</strong> in real-time.</p></li>
<li><p>ğŸ¤– These deployed models are often referred to as <strong>â€œmodel fit.â€</strong></p></li>
</ul>
<p><strong>Example</strong>:</p>
<ul class="simple">
<li><p>A deployed model in a spam filter application predicts whether an email is spam or not.</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="what-is-a-smart-application">
<h2>What is a Smart Application?<a class="headerlink" href="#what-is-a-smart-application" title="Link to this heading">#</a></h2>
<p>A <strong>smart application</strong> is an application that makes intelligent decisions using machine learning models.</p>
<section id="comparison">
<h3>Comparison:<a class="headerlink" href="#comparison" title="Link to this heading">#</a></h3>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p><strong>Feature</strong></p></th>
<th class="head"><p><strong>Normal Application</strong></p></th>
<th class="head"><p><strong>Smart Application</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Decision Making</strong></p></td>
<td><p>Based on fixed rules</p></td>
<td><p>Learns and adapts from data</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Self-Improvement</strong></p></td>
<td><p>âŒ No</p></td>
<td><p>âœ… Yes</p></td>
</tr>
<tr class="row-even"><td><p><strong>Intelligence</strong></p></td>
<td><p>âŒ None</p></td>
<td><p>âœ… Learns from experience</p></td>
</tr>
</tbody>
</table>
</div>
<p><strong>Example</strong>:</p>
<ul class="simple">
<li><p>Gmail uses a smart application to predict whether an email is spam.</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="accuracy-testing">
<h2>Accuracy Testing<a class="headerlink" href="#accuracy-testing" title="Link to this heading">#</a></h2>
<p>Before deployment, a model must be rigorously tested to ensure it performs well in various conditions.</p>
<section id="id2">
<h3>Key Aspects:<a class="headerlink" href="#id2" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p><strong>Accuracy</strong>: Measure of correct predictions.</p></li>
<li><p><strong>Generalization</strong>: Performance on unseen data.</p></li>
<li><p><strong>Edge Cases</strong>: Handling rare or unusual scenarios.</p></li>
</ol>
<p><strong>Outcome</strong>:</p>
<ul class="simple">
<li><p>Only models with <strong>high accuracy</strong> are deployed into production.</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="key-takeaways">
<h2>Key Takeaways<a class="headerlink" href="#key-takeaways" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p><strong>Machine Learning</strong>: Trains models to find patterns and make predictions.</p></li>
<li><p><strong>Model</strong>: A simplified representation of reality used to solve problems.</p></li>
<li><p><strong>Training</strong>: Teaching the model using data.</p></li>
<li><p><strong>Testing</strong>: Evaluating the modelâ€™s performance on unseen data.</p></li>
<li><p><strong>Deployment</strong>: Integrating the model into real-world applications.</p></li>
<li><p><strong>Smart Applications</strong>: Use machine learning to make intelligent decisions.</p></li>
<li><p><strong>Accuracy Testing</strong>: Ensures the model performs well before deployment.</p></li>
</ol>
</section>
</section>
<hr class="docutils" />
<section id="learning-a-function">
<h1>3. Learning a Function<a class="headerlink" href="#learning-a-function" title="Link to this heading">#</a></h1>
<hr class="docutils" />
<section id="understanding-function-learning-in-machine-learning">
<h2>Understanding Function Learning in Machine Learning<a class="headerlink" href="#understanding-function-learning-in-machine-learning" title="Link to this heading">#</a></h2>
<section id="what-is-learning-a-function">
<h3>What is Learning a Function?<a class="headerlink" href="#what-is-learning-a-function" title="Link to this heading">#</a></h3>
<p>Machine learning algorithms can be understood as <strong>learning a target function (f)</strong> that maps <strong>input variables (X)</strong> to an <strong>output variable (y)</strong>.</p>
<section id="mathematical-representation">
<h4>Mathematical Representation:<a class="headerlink" href="#mathematical-representation" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Output = f(Input)
y = f(X)
</pre></div>
</div>
</div>
</div>
<p>However, <strong>real-world data</strong> is often noisy, meaning the function includes some error component.</p>
</section>
<section id="error-inclusion">
<h4>Error Inclusion:<a class="headerlink" href="#error-inclusion" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>y = f(X) + error
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<hr class="docutils" />
<section id="why-is-learning-a-function-important">
<h2>Why is Learning a Function Important?<a class="headerlink" href="#why-is-learning-a-function-important" title="Link to this heading">#</a></h2>
<p>The <strong>goal of function learning</strong> in machine learning is to make <strong>accurate predictions</strong>.</p>
<section id="id3">
<h3>Key Points:<a class="headerlink" href="#id3" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>A function that has <strong>less error</strong> will make <strong>more accurate predictions</strong>.</p></li>
<li><p>This process is known as <strong>predictive modeling</strong>.</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="machine-learning-algorithms">
<h2>Machine Learning Algorithms<a class="headerlink" href="#machine-learning-algorithms" title="Link to this heading">#</a></h2>
<p>Machine learning algorithms are methods used to <strong>estimate the target function (f)</strong>.</p>
<section id="id4">
<h3>Key Aspects:<a class="headerlink" href="#id4" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>They help in predicting <strong>output variables (y)</strong> based on <strong>input variables (X)</strong>.</p></li>
<li><p>Different algorithms <strong>assume different forms</strong> for the function, e.g., <strong>linear vs. nonlinear</strong>.</p></li>
</ul>
</section>
<section id="types-of-function-assumptions">
<h3>Types of Function Assumptions<a class="headerlink" href="#types-of-function-assumptions" title="Link to this heading">#</a></h3>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Algorithm Type</p></th>
<th class="head"><p>Assumption about Function (f)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Linear Models</strong></p></td>
<td><p>Assume a straight-line relationship (e.g., Linear Regression)</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Nonlinear Models</strong></p></td>
<td><p>Assume a complex, curved relationship (e.g., Neural Networks)</p></td>
</tr>
</tbody>
</table>
</div>
</section>
</section>
<hr class="docutils" />
<section id="real-world-analogy-predicting-house-prices">
<h2>Real-World Analogy: Predicting House Prices<a class="headerlink" href="#real-world-analogy-predicting-house-prices" title="Link to this heading">#</a></h2>
<p>Imagine you want to predict the <strong>price of a house</strong> based on factors like <strong>size, location, and number of bedrooms</strong>.</p>
<section id="input-variables-x">
<h3>Input Variables (X):<a class="headerlink" href="#input-variables-x" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">X1</span> <span class="pre">=</span> <span class="pre">House</span> <span class="pre">Size</span> <span class="pre">(sq</span> <span class="pre">ft)</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">X2</span> <span class="pre">=</span> <span class="pre">Location</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">X3</span> <span class="pre">=</span> <span class="pre">Number</span> <span class="pre">of</span> <span class="pre">Bedrooms</span></code></p></li>
</ul>
</section>
<section id="output-variable-y">
<h3>Output Variable (y):<a class="headerlink" href="#output-variable-y" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">y</span> <span class="pre">=</span> <span class="pre">Predicted</span> <span class="pre">House</span> <span class="pre">Price</span></code></p></li>
</ul>
<p><strong>If the function learned by the model is accurate, it will predict house prices close to real values!</strong></p>
</section>
</section>
<hr class="docutils" />
<section id="interactive-code-example">
<h2>Interactive Code Example<a class="headerlink" href="#interactive-code-example" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span># Import necessary libraries
import numpy as np
from sklearn.linear_model import LinearRegression

# Sample Data (House Size vs. Price)
X = np.array([[1000], [1500], [2000], [2500], [3000]]) # Input (Size in sq ft)
y = np.array([150000, 200000, 250000, 300000, 350000]) # Output (Price in $)

# Train a Linear Regression Model
model = LinearRegression()
model.fit(X, y)

# Predict the price of a 2200 sq ft house
predicted_price = model.predict([[2200]])
print(f&quot;Predicted House Price: ${predicted_price[0]:,.2f}&quot;)
</pre></div>
</div>
</div>
</div>
</section>
<hr class="docutils" />
<section id="interview-prep-common-questions-concepts">
<h2>Interview Prep: Common Questions &amp; Concepts<a class="headerlink" href="#interview-prep-common-questions-concepts" title="Link to this heading">#</a></h2>
<section id="what-is-a-target-function-in-ml">
<h3>1. What is a target function in ML?<a class="headerlink" href="#what-is-a-target-function-in-ml" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>A mathematical relationship that maps inputs (<code class="docutils literal notranslate"><span class="pre">X</span></code>) to an output (<code class="docutils literal notranslate"><span class="pre">y</span></code>).</p></li>
</ul>
</section>
<section id="why-does-the-error-exist-in-function-learning">
<h3>2. Why does the error exist in function learning?<a class="headerlink" href="#why-does-the-error-exist-in-function-learning" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Due to noise, missing data, or limitations in the model.</p></li>
</ul>
</section>
<section id="what-is-the-difference-between-linear-and-nonlinear-function-assumptions">
<h3>3. What is the difference between linear and nonlinear function assumptions?<a class="headerlink" href="#what-is-the-difference-between-linear-and-nonlinear-function-assumptions" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Linear Models:</strong> Assume a direct proportional relationship.</p></li>
<li><p><strong>Nonlinear Models:</strong> Allow for more complex, flexible relationships.</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="success-metrics-how-to-evaluate-a-learned-function">
<h2>Success Metrics: How to Evaluate a Learned Function?<a class="headerlink" href="#success-metrics-how-to-evaluate-a-learned-function" title="Link to this heading">#</a></h2>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Metric</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Mean Squared Error (MSE)</strong></p></td>
<td><p>Measures average squared difference between predicted &amp; actual values.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>RÂ² Score (R-Squared)</strong></p></td>
<td><p>Measures how well the model explains the variance in data.</p></td>
</tr>
<tr class="row-even"><td><p><strong>Cross-Validation Score</strong></p></td>
<td><p>Checks how well the function generalizes to unseen data.</p></td>
</tr>
</tbody>
</table>
</div>
<p><strong>Lower MSE</strong> &amp; <strong>Higher RÂ² Score</strong> = <strong>Better Function Learning!</strong></p>
</section>
<hr class="docutils" />
<section id="id5">
<h2>Conclusion<a class="headerlink" href="#id5" title="Link to this heading">#</a></h2>
<p>Machine learning is all about learning functions that map inputs to outputs. The more accurately this function is learned (with minimal error), the better the model will make predictions. Different algorithms approach this task in varied ways based on the assumptions they make about the function.</p>
</section>
</section>
<hr class="docutils" />
<section id="bias-variance-tradeoff">
<h1>5. Bias-Variance Tradeoff<a class="headerlink" href="#bias-variance-tradeoff" title="Link to this heading">#</a></h1>
<p>The <strong>Bias-Variance Tradeoff</strong> is a cornerstone concept in machine learning that addresses the challenge of balancing two sources of error bias and variance to ensure a model generalizes well to unseen data. This tradeoff is critical when designing models, as it influences their predictive performance.</p>
<section id="what-is-the-bias-variance-tradeoff">
<h2>What is the Bias-Variance Tradeoff?<a class="headerlink" href="#what-is-the-bias-variance-tradeoff" title="Link to this heading">#</a></h2>
<p>In machine learning, a modelâ€™s error when predicting on new data can be broken down into three components:</p>
<ol class="arabic simple">
<li><p><strong>Bias</strong>: The error due to overly simplistic assumptions in the model. High bias occurs when a model is too basic to capture the underlying patterns in the data, leading to <strong>underfitting</strong>. For instance, using a linear model to fit a nonlinear relationship introduces high bias.</p></li>
<li><p><strong>Variance</strong>: The error due to sensitivity to small fluctuations in the training data. High variance arises when a model is too complex and fits the noise in the training data, resulting in <strong>overfitting</strong>. Such models perform well on training data but poorly on new data.</p></li>
<li><p><strong>Irreducible Error</strong>: The inherent noise in the data that cannot be eliminated, regardless of the model.</p></li>
</ol>
<p>The <strong>total error</strong> of a model can be expressed as:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>   Total Error = BiasÂ² + Variance + Noise
</pre></div>
</div>
</div>
</div>
<p>The tradeoff arises because decreasing bias (e.g., by increasing model complexity) typically increases variance, and vice versa. The goal is to find an optimal model complexity that minimizes the total error, striking a balance between underfitting and overfitting.</p>
</section>
<section id="formal-decomposition">
<h2>Formal Decomposition<a class="headerlink" href="#formal-decomposition" title="Link to this heading">#</a></h2>
<p>Suppose we aim to approximate a true function ( f(x) ) with a model ( \hat{f}(x) ), trained on a dataset with noise ( y = f(x) + \epsilon ), where ( \epsilon ) is random noise with mean 0 and variance ( \sigma^2 ). The expected squared error at a point ( x ) is:</p>
<p>[ E[(y - \hat{f}(x))^2] = (E[\hat{f}(x)] - f(x))^2 + E[(\hat{f}(x) - E[\hat{f}(x)])^2] + \sigma^2 ]</p>
<ul class="simple">
<li><p><strong>Bias</strong>: ( E[\hat{f}(x)] - f(x) ), the difference between the expected prediction and the true value.</p></li>
<li><p><strong>Variance</strong>: ( E[(\hat{f}(x) - E[\hat{f}(x)])^2] ), the variability of the modelâ€™s predictions across different training sets.</p></li>
<li><p><strong>Irreducible Error</strong>: ( \sigma^2 ), the noise variance.</p></li>
</ul>
<p>The tradeoff is managed by tuning model complexity to minimize (BiasÂ² + Variance).</p>
</section>
<section id="breaking-down-prediction-errors">
<h2><strong>Breaking Down Prediction Errors</strong><a class="headerlink" href="#breaking-down-prediction-errors" title="Link to this heading">#</a></h2>
<p>The total prediction error of a model can be split into three parts:</p>
<ol class="arabic simple">
<li><p><strong>BiasÂ²</strong>: Error from oversimplified assumptions (squared to ensure itâ€™s positive).</p></li>
<li><p><strong>Variance</strong>: Error from sensitivity to training data changes.</p></li>
<li><p><strong>Irreducible Error</strong>: Noise thatâ€™s always present.</p></li>
</ol>
</section>
<section id="the-bias-variance-tradeoff-explained">
<h2><strong>The Bias-Variance Tradeoff Explained</strong><a class="headerlink" href="#the-bias-variance-tradeoff-explained" title="Link to this heading">#</a></h2>
<p>The tradeoff is about finding the â€œsweet spotâ€ in model complexity:</p>
<ul class="simple">
<li><p><strong>Increase Complexity</strong>: Bias decreases (better fit to patterns), but variance increases (more sensitivity to noise).</p></li>
<li><p><strong>Decrease Complexity</strong>: Variance decreases (more stable predictions), but bias increases (misses patterns).</p></li>
</ul>
<section id="visualizing-the-tradeoff">
<h3><strong>Visualizing the Tradeoff</strong><a class="headerlink" href="#visualizing-the-tradeoff" title="Link to this heading">#</a></h3>
<p>Imagine a dartboard:</p>
<ul class="simple">
<li><p><strong>High Bias</strong>: Darts consistently hit far from the bullseye (underfitting).</p></li>
<li><p><strong>High Variance</strong>: Darts are scattered all over the board (overfitting).</p></li>
<li><p><strong>Balanced Model</strong>: Darts cluster near the bullseye (good generalization).</p></li>
</ul>
</section>
<section id="bias-variance-scenarios">
<h3><strong>Bias-Variance Scenarios</strong><a class="headerlink" href="#bias-variance-scenarios" title="Link to this heading">#</a></h3>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p><strong>Bias</strong></p></th>
<th class="head"><p><strong>Variance</strong></p></th>
<th class="head"><p><strong>Result</strong></p></th>
<th class="head"><p><strong>Accuracy</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Low</p></td>
<td><p>Low</p></td>
<td><p>Ideal model</p></td>
<td><p>High âœ…</p></td>
</tr>
<tr class="row-odd"><td><p>Low</p></td>
<td><p>High</p></td>
<td><p>Overfitting</p></td>
<td><p>Low âŒ</p></td>
</tr>
<tr class="row-even"><td><p>High</p></td>
<td><p>Low</p></td>
<td><p>Underfitting</p></td>
<td><p>Low âŒ</p></td>
</tr>
<tr class="row-odd"><td><p>High</p></td>
<td><p>High</p></td>
<td><p>Worst case</p></td>
<td><p>Very Low âŒ</p></td>
</tr>
</tbody>
</table>
</div>
</section>
</section>
<section id="examples-illustrating-the-tradeoff">
<h2>Examples Illustrating the Tradeoff<a class="headerlink" href="#examples-illustrating-the-tradeoff" title="Link to this heading">#</a></h2>
<section id="example-1-linear-regression-on-nonlinear-data">
<h3>Example 1: Linear Regression on Nonlinear Data<a class="headerlink" href="#example-1-linear-regression-on-nonlinear-data" title="Link to this heading">#</a></h3>
<p>Imagine data generated by ( y = x^2 + \epsilon ), where ( \epsilon ) is noise. Fitting a linear model ( y = mx + b ) results in high bias because it cannot capture the quadratic relationship, leading to underfitting. Conversely, fitting a high-degree polynomial (e.g., degree 15) might perfectly match the training data, including noise, but its predictions vary widely with different training samples, indicating high variance and overfitting.</p>
</section>
<section id="example-2-decision-trees">
<h3>Example 2: Decision Trees<a class="headerlink" href="#example-2-decision-trees" title="Link to this heading">#</a></h3>
<p>A shallow decision tree (e.g., depth 2) has high bias, making broad assumptions that miss intricate patterns. A deep tree (e.g., depth 20) has high variance, fitting the training data too closely, including noise, and failing to generalize.</p>
<p>In both cases, the optimal model complexityâ€”e.g., a polynomial of degree 2 or a tree of moderate depthâ€”balances bias and variance.</p>
</section>
</section>
<section id="tools-and-methods-to-manage-the-tradeoff">
<h2>Tools and Methods to Manage the Tradeoff<a class="headerlink" href="#tools-and-methods-to-manage-the-tradeoff" title="Link to this heading">#</a></h2>
<p>Several techniques help navigate the bias-variance tradeoff:</p>
<ol class="arabic simple">
<li><p><strong>Cross-Validation</strong>: Splits data into training and validation sets multiple times to estimate generalization error, aiding in model complexity selection.</p></li>
<li><p><strong>Regularization</strong>: Adds a penalty to model complexity (e.g., Ridge or Lasso regression), reducing variance by introducing controlled bias.</p></li>
<li><p><strong>Ensemble Methods</strong>:</p>
<ul class="simple">
<li><p><strong>Bagging</strong> (e.g., Random Forests): Reduces variance by averaging predictions from models trained on different data subsets.</p></li>
<li><p><strong>Boosting</strong> (e.g., Gradient Boosting): Reduces bias by iteratively correcting errors.</p></li>
</ul>
</li>
<li><p><strong>Model Selection</strong>: Choosing an appropriate algorithm or hyperparameters (e.g., polynomial degree, tree depth) based on validation performance.</p></li>
<li><p><strong>Data Augmentation</strong>: Increasing training data size can reduce variance by making the model less sensitive to specific samples.</p></li>
</ol>
</section>
<section id="a-one-stop-python-solution">
<h2>A One-Stop Python Solution<a class="headerlink" href="#a-one-stop-python-solution" title="Link to this heading">#</a></h2>
<p>Letâ€™s implement a demonstration using polynomial regression to visualize the bias-variance tradeoff. Weâ€™ll generate synthetic data from ( y = \sin(x) + \epsilon ), fit polynomials of varying degrees, and compute bias, variance, and total error.</p>
<section id="complete-python-code">
<h3>Complete Python Code<a class="headerlink" href="#complete-python-code" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline

# Define the true function
def true_function(x):
    return np.sin(x)

# Generate noisy training data
def generate_data(n_samples=20, noise=0.1):
    x = np.random.uniform(0, 2*np.pi, n_samples)
    y = true_function(x) + np.random.normal(0, noise, n_samples)
    return x, y

# Parameters
n_train_sets = 200  # Number of training sets to simulate
n_samples = 20      # Samples per training set
noise = 0.1         # Noise level
degrees = range(1, 16)  # Polynomial degrees to test
x_test = np.linspace(0, 2*np.pi, 100)  # Fixed test set
y_test_true = true_function(x_test)    # True function values

# Compute bias, variance, and total error for each degree
bias_squared = []
variance = []
total_error = []

for degree in degrees:
    predictions = []
    for _ in range(n_train_sets):
        x_train, y_train = generate_data(n_samples, noise)
        # Fit polynomial regression model
        model = make_pipeline(PolynomialFeatures(degree), LinearRegression())
        model.fit(x_train[:, np.newaxis], y_train)
        y_pred = model.predict(x_test[:, np.newaxis])
        predictions.append(y_pred)
    
    predictions = np.array(predictions)  # Shape: (n_train_sets, n_test_points)
    avg_pred = np.mean(predictions, axis=0)  # Average prediction
    bias = avg_pred - y_test_true            # Bias at each test point
    bias_squared_degree = np.mean(bias**2)   # Average squared bias
    variance_degree = np.mean(np.var(predictions, axis=0))  # Average variance
    total_error_degree = np.mean((predictions - y_test_true)**2)  # Average squared error
    
    bias_squared.append(bias_squared_degree)
    variance.append(variance_degree)
    total_error.append(total_error_degree)

# Plot Bias^2, Variance, and Total Error
plt.figure(figsize=(10, 6))
plt.plot(degrees, bias_squared, label=&#39;Bias^2&#39;)
plt.plot(degrees, variance, label=&#39;Variance&#39;)
plt.plot(degrees, total_error, label=&#39;Total Error&#39;)
plt.xlabel(&#39;Polynomial Degree&#39;)
plt.ylabel(&#39;Error&#39;)
plt.legend()
plt.title(&#39;Bias-Variance Tradeoff&#39;)
plt.show()

# Visualize fitted models for selected degrees
degrees_to_plot = [1, 3, 15]
plt.figure(figsize=(15, 5))
for i, degree in enumerate(degrees_to_plot):
    plt.subplot(1, 3, i+1)
    plt.plot(x_test, y_test_true, label=&#39;True function&#39;, color=&#39;black&#39;)
    for _ in range(10):
        x_train, y_train = generate_data(n_samples, noise)
        model = make_pipeline(PolynomialFeatures(degree), LinearRegression())
        model.fit(x_train[:, np.newaxis], y_train)
        y_pred = model.predict(x_test[:, np.newaxis])
        plt.plot(x_test, y_pred, color=&#39;blue&#39;, alpha=0.2)
    plt.title(f&#39;Degree {degree}&#39;)
    plt.legend()
plt.show()
</pre></div>
</div>
</div>
</div>
</section>
<section id="explanation-of-the-code">
<h3>Explanation of the Code<a class="headerlink" href="#explanation-of-the-code" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p><strong>Data Generation</strong>: We simulate data from ( y = \sin(x) + \epsilon ), where ( \epsilon \sim N(0, 0.1) ), over the interval ( [0, 2\pi] ).</p></li>
<li><p><strong>Model Fitting</strong>: For each polynomial degree (1 to 15), we train 200 models on different training sets and predict on a fixed test set.</p></li>
<li><p><strong>Metrics Calculation</strong>:</p>
<ul class="simple">
<li><p><strong>Bias^2</strong>: Mean squared difference between the average prediction and the true function.</p></li>
<li><p><strong>Variance</strong>: Mean variance of predictions across models.</p></li>
<li><p><strong>Total Error</strong>: Mean squared error between predictions and the true function (approximates ( \text{Bias}^2 + \text{Variance} )).</p></li>
</ul>
</li>
<li><p><strong>Visualization</strong>:</p>
<ul class="simple">
<li><p>The first plot shows how ( \text{Bias}^2 ) decreases, ( \text{Variance} ) increases, and ( \text{Total Error} ) forms a U-shape with increasing degree.</p></li>
<li><p>The second plot visualizes fitted curves for degrees 1, 3, and 15, illustrating high bias (degree 1), balanced fit (degree 3), and high variance (degree 15).</p></li>
</ul>
</li>
</ol>
</section>
<section id="expected-output">
<h3>Expected Output<a class="headerlink" href="#expected-output" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Bias-Variance Plot</strong>: Bias^2 starts high and drops, variance starts low and rises, and total error has a minimum at an intermediate degree (e.g., 3â€“5).</p></li>
<li><p><strong>Fitted Curves</strong>: Degree 1 fits are straight lines (high bias), degree 3 fits approximate the sine wave, and degree 15 fits vary wildly (high variance).</p></li>
</ul>
</section>
</section>
<section id="id6">
<h2>Conclusion<a class="headerlink" href="#id6" title="Link to this heading">#</a></h2>
<p>The Bias-Variance Tradeoff emphasizes the need to balance model simplicity and flexibility. Too simple a model underfits with high bias; too complex a model overfits with high variance.</p>
</section>
</section>
<hr class="docutils" />
<section id="underfitting-and-overfitting">
<h1>6. Underfitting and Overfitting<a class="headerlink" href="#underfitting-and-overfitting" title="Link to this heading">#</a></h1>
<hr class="docutils" />
<section id="key-terms-to-understand">
<h2><strong>Key Terms to Understand</strong><a class="headerlink" href="#key-terms-to-understand" title="Link to this heading">#</a></h2>
<p>To get underfitting and overfitting, you need to know these basics:</p>
<ul class="simple">
<li><p><strong>Noise</strong>: Random or useless data that confuses the model. Itâ€™s always there, but a good model ignores it.</p></li>
<li><p><strong>Bias</strong>: Errors from a model being too simple. High bias causes underfitting.</p></li>
<li><p><strong>Variance</strong>: Errors from a model being too sensitive to the training data. High variance causes overfitting.</p></li>
</ul>
<section id="the-goldilocks-zone-balanced-model">
<h3><strong>The Goldilocks Zone: Balanced Model</strong><a class="headerlink" href="#the-goldilocks-zone-balanced-model" title="Link to this heading">#</a></h3>
<p>A good model should:</p>
<ol class="arabic simple">
<li><p><strong>Learn patterns</strong> from training data.</p></li>
<li><p><strong>Generalize well</strong> to unseen data meaning:</p>
<ul class="simple">
<li><p><strong>Good training performance</strong> âœ…</p></li>
<li><p><strong>Good test performance</strong> âœ…</p></li>
<li><p><strong>Balanced bias and variance</strong> âœ…</p></li>
</ul>
</li>
</ol>
</section>
</section>
<hr class="docutils" />
<section id="understanding-underfitting-and-overfitting">
<h2>Understanding Underfitting and Overfitting<a class="headerlink" href="#understanding-underfitting-and-overfitting" title="Link to this heading">#</a></h2>
<p>In machine learning, the goal is to build a model that generalizes well to unseen data. However, two common pitfalls can prevent this: <strong>underfitting</strong> and <strong>overfitting</strong>.</p>
<section id="underfitting">
<h3><strong>Underfitting</strong><a class="headerlink" href="#underfitting" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Definition:</strong> Underfitting occurs when a model is too simple to capture the underlying patterns in the data. It fails to learn the relationships effectively, leading to poor performance on both the training data and unseen test data.</p></li>
<li><p><strong>Characteristics:</strong></p>
<ul>
<li><p>High error on training data (poor fit).</p></li>
<li><p>High error on test data (poor generalization).</p></li>
</ul>
</li>
<li><p><strong>Cause:</strong> The model lacks sufficient complexity (e.g., a linear model applied to nonlinear data) or is undertrained.</p></li>
</ul>
</section>
<section id="overfitting">
<h3><strong>Overfitting</strong><a class="headerlink" href="#overfitting" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Definition:</strong> Overfitting happens when a model is too complex and learns not only the underlying patterns but also the noise or random fluctuations in the training data. While it performs well on the training set, it fails to generalize to new data.</p></li>
<li><p><strong>Characteristics:</strong></p>
<ul>
<li><p>Low error on training data (excellent fit).</p></li>
<li><p>High error on test data (poor generalization).</p></li>
</ul>
</li>
<li><p><strong>Cause:</strong> Excessive model complexity (e.g., a high-degree polynomial) or insufficient regularization.</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="examples">
<h2>Examples<a class="headerlink" href="#examples" title="Link to this heading">#</a></h2>
<section id="underfitting-example">
<h3><strong>Underfitting Example</strong><a class="headerlink" href="#underfitting-example" title="Link to this heading">#</a></h3>
<p>Imagine trying to fit a quadratic relationship (e.g., ( y = x^2 )) using a simple linear regression model (e.g., ( y = mx + b )). The straight line cannot capture the curve, resulting in a poor fit to both training and test data.</p>
</section>
<section id="overfitting-example">
<h3><strong>Overfitting Example</strong><a class="headerlink" href="#overfitting-example" title="Link to this heading">#</a></h3>
<p>Now consider fitting a simple linear relationship (e.g., ( y = 2x + 1 )) with a 15th-degree polynomial. The model will wiggle excessively to match every training point, including noise, leading to a great fit on training data but poor performance on unseen data.</p>
</section>
</section>
<section id="example-studying-for-a-math-exam">
<h2><strong>Example: Studying for a Math Exam</strong><a class="headerlink" href="#example-studying-for-a-math-exam" title="Link to this heading">#</a></h2>
<p>Imagine three students preparing for a math test. Their approaches show how underfitting, overfitting, and a good fit work:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p><strong>Student</strong></p></th>
<th class="head"><p><strong>Study Method</strong></p></th>
<th class="head"><p><strong>Exam Result</strong></p></th>
<th class="head"><p><strong>ML Match</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Student 1</p></td>
<td><p>Only learned addition</p></td>
<td><p>Failed most questions</p></td>
<td><p>Underfitting ğŸ“‰</p></td>
</tr>
<tr class="row-odd"><td><p>Student 2</p></td>
<td><p>Memorized one textbook word-for-word</p></td>
<td><p>Failed new question types</p></td>
<td><p>Overfitting ğŸ“‰</p></td>
</tr>
<tr class="row-even"><td><p>Student 3</p></td>
<td><p>Studied all topics, practiced widely</p></td>
<td><p>Did well on all questions</p></td>
<td><p>Good Fit âœ…</p></td>
</tr>
</tbody>
</table>
</div>
<ul class="simple">
<li><p><strong>Student 1 (Underfitting)</strong>: Too little effort, missed the big picture.</p></li>
<li><p><strong>Student 2 (Overfitting)</strong>: Too much focus on one thing, no flexibility.</p></li>
<li><p><strong>Student 3 (Good Fit)</strong>: Balanced effort, ready for anything.</p></li>
</ul>
<p>This is like machine learning:</p>
<ul class="simple">
<li><p><strong>Underfitting</strong>: The model doesnâ€™t learn enough.</p></li>
<li><p><strong>Overfitting</strong>: The model learns too much, including useless details.</p></li>
<li><p><strong>Good Fit</strong>: The model learns just what it needs to succeed.</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="tools-and-methods-to-address-underfitting-and-overfitting">
<h2>Tools and Methods to Address Underfitting and Overfitting<a class="headerlink" href="#tools-and-methods-to-address-underfitting-and-overfitting" title="Link to this heading">#</a></h2>
<p>To detect and mitigate these issues, we use several techniques:</p>
<ol class="arabic simple">
<li><p><strong>Model Evaluation Metrics</strong></p>
<ul class="simple">
<li><p>Use metrics like <strong>Mean Squared Error (MSE)</strong> or <strong>R-squared</strong> to quantify performance on training and test sets.</p></li>
<li><p>High MSE on both indicates underfitting; low training MSE but high test MSE suggests overfitting.</p></li>
</ul>
</li>
<li><p><strong>Cross-Validation</strong></p>
<ul class="simple">
<li><p>Techniques like <strong>k-fold cross-validation</strong> assess how well the model generalizes to unseen data by splitting the dataset into multiple training and validation subsets.</p></li>
</ul>
</li>
<li><p><strong>Regularization</strong></p>
<ul class="simple">
<li><p>Methods like <strong>L1 (Lasso)</strong> and <strong>L2 (Ridge)</strong> regularization add penalties to the modelâ€™s coefficients, reducing complexity and preventing overfitting.</p></li>
</ul>
</li>
<li><p><strong>Learning Curves</strong></p>
<ul class="simple">
<li><p>Plot training and validation errors against the number of training examples to visualize underfitting (high errors converging) or overfitting (large gap between training and validation errors).</p></li>
</ul>
</li>
<li><p><strong>Model Selection</strong></p>
<ul class="simple">
<li><p>Choose an appropriate model complexity (e.g., polynomial degree) based on the dataâ€™s underlying patterns.</p></li>
</ul>
</li>
</ol>
</section>
<hr class="docutils" />
<section id="python-code-demonstration">
<h2>Python Code Demonstration<a class="headerlink" href="#python-code-demonstration" title="Link to this heading">#</a></h2>
<p>Letâ€™s implement these concepts with a synthetic dataset, showing examples of underfitting, overfitting, and an optimal model. Weâ€™ll use Python libraries like <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> and <code class="docutils literal notranslate"><span class="pre">matplotlib</span></code>.</p>
<section id="code">
<h3>Code<a class="headerlink" href="#code" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, learning_curve
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline
from sklearn.metrics import mean_squared_error

# Generate synthetic data (sinusoidal with noise)
np.random.seed(0)
X = np.sort(5 * np.random.rand(80, 1), axis=0)
y = np.sin(X).ravel() + np.random.normal(0, 0.1, X.shape[0])

# Split data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

# Function to plot learning curves
def plot_learning_curve(estimator, title, X, y, cv=None, train_sizes=np.linspace(0.1, 1.0, 5)):
    plt.figure()
    plt.title(title)
    plt.xlabel(&quot;Training examples&quot;)
    plt.ylabel(&quot;Score&quot;)
    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, train_sizes=train_sizes)
    train_scores_mean = np.mean(train_scores, axis=1)
    train_scores_std = np.std(train_scores, axis=1)
    test_scores_mean = np.mean(test_scores, axis=1)
    test_scores_std = np.std(test_scores, axis=1)
    plt.grid()
    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=&quot;r&quot;)
    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=&quot;g&quot;)
    plt.plot(train_sizes, train_scores_mean, &#39;o-&#39;, color=&quot;r&quot;, label=&quot;Training score&quot;)
    plt.plot(train_sizes, test_scores_mean, &#39;o-&#39;, color=&quot;g&quot;, label=&quot;Cross-validation score&quot;)
    plt.legend(loc=&quot;best&quot;)
    return plt

# 1. Underfitting: Linear Regression
linear_model = LinearRegression()
linear_model.fit(X_train, y_train)
y_pred_train_linear = linear_model.predict(X_train)
y_pred_test_linear = linear_model.predict(X_test)
print(&quot;Underfitting - Linear Regression&quot;)
print(&quot;Train MSE:&quot;, mean_squared_error(y_train, y_pred_train_linear))
print(&quot;Test MSE:&quot;, mean_squared_error(y_test, y_pred_test_linear))

# 2. Overfitting: High-degree polynomial regression (degree=15)
degree = 15
poly_model = make_pipeline(PolynomialFeatures(degree), LinearRegression())
poly_model.fit(X_train, y_train)
y_pred_train_poly = poly_model.predict(X_train)
y_pred_test_poly = poly_model.predict(X_test)
print(&quot;\nOverfitting - Polynomial Regression (degree=15)&quot;)
print(&quot;Train MSE:&quot;, mean_squared_error(y_train, y_pred_train_poly))
print(&quot;Test MSE:&quot;, mean_squared_error(y_test, y_pred_test_poly))

# 3. Optimal Model: Polynomial regression (degree=2) with Ridge regularization
optimal_model = make_pipeline(PolynomialFeatures(2), Ridge(alpha=0.1))
optimal_model.fit(X_train, y_train)
y_pred_train_optimal = optimal_model.predict(X_train)
y_pred_test_optimal = optimal_model.predict(X_test)
print(&quot;\nOptimal Model - Polynomial Regression (degree=2) with Ridge&quot;)
print(&quot;Train MSE:&quot;, mean_squared_error(y_train, y_pred_train_optimal))
print(&quot;Test MSE:&quot;, mean_squared_error(y_test, y_pred_test_optimal))

# Plotting the results
plt.figure(figsize=(14, 4))

# Underfitting plot
plt.subplot(1, 3, 1)
plt.scatter(X_train, y_train, color=&#39;blue&#39;, label=&#39;Train data&#39;)
plt.scatter(X_test, y_test, color=&#39;green&#39;, label=&#39;Test data&#39;)
plt.plot(X, linear_model.predict(X), color=&#39;red&#39;, label=&#39;Linear model&#39;)
plt.title(&#39;Underfitting - Linear Regression&#39;)
plt.legend()

# Overfitting plot
plt.subplot(1, 3, 2)
plt.scatter(X_train, y_train, color=&#39;blue&#39;, label=&#39;Train data&#39;)
plt.scatter(X_test, y_test, color=&#39;green&#39;, label=&#39;Test data&#39;)
X_plot = np.linspace(0, 5, 100).reshape(-1, 1)
plt.plot(X_plot, poly_model.predict(X_plot), color=&#39;red&#39;, label=&#39;Polynomial (degree=15)&#39;)
plt.title(&#39;Overfitting - Polynomial Regression&#39;)
plt.legend()

# Optimal model plot
plt.subplot(1, 3, 3)
plt.scatter(X_train, y_train, color=&#39;blue&#39;, label=&#39;Train data&#39;)
plt.scatter(X_test, y_test, color=&#39;green&#39;, label=&#39;Test data&#39;)
plt.plot(X_plot, optimal_model.predict(X_plot), color=&#39;red&#39;, label=&#39;Optimal (degree=2)&#39;)
plt.title(&#39;Optimal Model&#39;)
plt.legend()

plt.show()

# Learning curves for the optimal model
plot_learning_curve(optimal_model, &quot;Learning Curves (Optimal Model)&quot;, X, y, cv=5)
plt.show()
</pre></div>
</div>
</div>
</div>
</section>
</section>
<hr class="docutils" />
<section id="id7">
<h2>Explanation of the Code<a class="headerlink" href="#id7" title="Link to this heading">#</a></h2>
<section id="dataset">
<h3><strong>Dataset</strong><a class="headerlink" href="#dataset" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>We generate a synthetic dataset where ( y = \sin(x) + \text{noise} ), simulating a nonlinear pattern with some randomness.</p></li>
</ul>
</section>
<section id="models">
<h3><strong>Models</strong><a class="headerlink" href="#models" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p><strong>Underfitting: Linear Regression</strong></p>
<ul class="simple">
<li><p>A straight line is fitted to the sinusoidal data.</p></li>
<li><p><strong>Result:</strong> High MSE on both training (~0.24) and test (~0.23) sets, indicating the model is too simple to capture the pattern.</p></li>
</ul>
</li>
<li><p><strong>Overfitting: Polynomial Regression (degree=15)</strong></p>
<ul class="simple">
<li><p>A 15th-degree polynomial fits the training data almost perfectly, including noise.</p></li>
<li><p><strong>Result:</strong> Very low training MSE (~0.01) but high test MSE (~0.25), showing poor generalization.</p></li>
</ul>
</li>
<li><p><strong>Optimal Model: Polynomial Regression (degree=2) with Ridge</strong></p>
<ul class="simple">
<li><p>A 2nd-degree polynomial with Ridge regularization balances complexity and generalization.</p></li>
<li><p><strong>Result:</strong> Reasonable MSE on training (~0.05) and test (~0.06), indicating a good fit.</p></li>
</ul>
</li>
</ol>
</section>
<section id="visualizations">
<h3><strong>Visualizations</strong><a class="headerlink" href="#visualizations" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Plots:</strong> Three subplots show the data and fitted models for underfitting, overfitting, and the optimal case.</p></li>
<li><p><strong>Learning Curves:</strong> For the optimal model, training and validation scores converge, confirming good generalization.</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><strong>Underfitting:</strong> Too simple (e.g., linear model on nonlinear data). Fix by increasing model complexity or training time.</p></li>
<li><p><strong>Overfitting:</strong> Too complex (e.g., high-degree polynomial). Fix by reducing complexity, adding regularization, or collecting more data.</p></li>
<li><p><strong>Tools:</strong> MSE, cross-validation, regularization, learning curves, and model selection help diagnose and resolve these issues.</p></li>
</ul>
<hr class="docutils" />
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./contents\3_ml"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../2_pandas/5_feature_engineering.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><strong>What is Feature Engineering?</strong></p>
      </div>
    </a>
    <a class="right-next"
       href="2_data_preparation.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">2ï¸âƒ£ Data Handling</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">ML Foundational</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-machine-learning">ğŸš€ 1. Introduction to Machine Learning</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-machine-learning">ğŸ¤– What is Machine Learning?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-aspects">ğŸ” Key Aspects:</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-a-program">ğŸ–¥ï¸ What is a Program?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#features">âœ… Features:</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-an-algorithm">ğŸ“œ What is an Algorithm?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-a-machine-learning-algorithm">ğŸ¤– What is a Machine Learning Algorithm?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#difference-between-normal-machine-learning-algorithms">ğŸ”„ Difference Between Normal &amp; Machine Learning Algorithms</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-machine-learning">ğŸ“ˆ Why Machine Learning?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#major-use-cases">ğŸŒ Major Use Cases:</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#definitions-of-machine-learning">ğŸ›ï¸ Definitions of Machine Learning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#arthur-samuels-definition-1959">ğŸ”¬ Arthur Samuelâ€™s Definition (1959):</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ai-vs-ml-vs-deep-learning">ğŸ† AI vs ML vs Deep Learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#human-vs-computer-decision-making">ğŸ§  Human vs Computer Decision-Making</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#how-do-machines-think">ğŸ’¡ How Do Machines â€œThinkâ€?</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#real-world-applications-of-machine-learning">ğŸŒ Real-World Applications of Machine Learning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gmail-spam-filter">âœ‰ï¸ <strong>Gmail Spam Filter</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#banking-loan-credit-card-approval">ğŸ¦ <strong>Banking Loan/Credit Card Approval</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">ğŸ”¥ Conclusion</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#terminology">2. Terminology</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">What is Machine Learning?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-points">Key Points:</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-a-model">What is a Model?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#types-of-models">Types of Models:</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-the-model">Training the Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-does-the-model-learn">How Does the Model Learn?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-concepts">Key Concepts:</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#testing-the-model">Testing the Model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-steps">Key Steps:</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-deployment">Model Deployment</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-a-smart-application">What is a Smart Application?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#comparison">Comparison:</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#accuracy-testing">Accuracy Testing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Key Aspects:</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-a-function">3. Learning a Function</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-function-learning-in-machine-learning">Understanding Function Learning in Machine Learning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-learning-a-function">What is Learning a Function?</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#mathematical-representation">Mathematical Representation:</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#error-inclusion">Error Inclusion:</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-is-learning-a-function-important">Why is Learning a Function Important?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">Key Points:</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#machine-learning-algorithms">Machine Learning Algorithms</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">Key Aspects:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#types-of-function-assumptions">Types of Function Assumptions</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#real-world-analogy-predicting-house-prices">Real-World Analogy: Predicting House Prices</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#input-variables-x">Input Variables (X):</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#output-variable-y">Output Variable (y):</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interactive-code-example">Interactive Code Example</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interview-prep-common-questions-concepts">Interview Prep: Common Questions &amp; Concepts</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-a-target-function-in-ml">1. What is a target function in ML?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-does-the-error-exist-in-function-learning">2. Why does the error exist in function learning?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-the-difference-between-linear-and-nonlinear-function-assumptions">3. What is the difference between linear and nonlinear function assumptions?</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#success-metrics-how-to-evaluate-a-learned-function">Success Metrics: How to Evaluate a Learned Function?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">Conclusion</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#bias-variance-tradeoff">5. Bias-Variance Tradeoff</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-the-bias-variance-tradeoff">What is the Bias-Variance Tradeoff?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#formal-decomposition">Formal Decomposition</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#breaking-down-prediction-errors"><strong>Breaking Down Prediction Errors</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-bias-variance-tradeoff-explained"><strong>The Bias-Variance Tradeoff Explained</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizing-the-tradeoff"><strong>Visualizing the Tradeoff</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bias-variance-scenarios"><strong>Bias-Variance Scenarios</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#examples-illustrating-the-tradeoff">Examples Illustrating the Tradeoff</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-1-linear-regression-on-nonlinear-data">Example 1: Linear Regression on Nonlinear Data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-2-decision-trees">Example 2: Decision Trees</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tools-and-methods-to-manage-the-tradeoff">Tools and Methods to Manage the Tradeoff</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-one-stop-python-solution">A One-Stop Python Solution</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#complete-python-code">Complete Python Code</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#explanation-of-the-code">Explanation of the Code</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#expected-output">Expected Output</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">Conclusion</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#underfitting-and-overfitting">6. Underfitting and Overfitting</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-terms-to-understand"><strong>Key Terms to Understand</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-goldilocks-zone-balanced-model"><strong>The Goldilocks Zone: Balanced Model</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-underfitting-and-overfitting">Understanding Underfitting and Overfitting</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#underfitting"><strong>Underfitting</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#overfitting"><strong>Overfitting</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#examples">Examples</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#underfitting-example"><strong>Underfitting Example</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#overfitting-example"><strong>Overfitting Example</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-studying-for-a-math-exam"><strong>Example: Studying for a Math Exam</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tools-and-methods-to-address-underfitting-and-overfitting">Tools and Methods to Address Underfitting and Overfitting</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#python-code-demonstration">Python Code Demonstration</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#code">Code</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">Explanation of the Code</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset"><strong>Dataset</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#models"><strong>Models</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizations"><strong>Visualizations</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a></li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Gajanesh
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      Â© Copyright Â© 2025 Gajanesh. All rights reserved..
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>