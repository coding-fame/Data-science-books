{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64a0d26e",
   "metadata": {},
   "source": [
    "# Train & Test Datasets in Python\n",
    "\n",
    "---\n",
    "\n",
    "## Types of Datasets in Machine Learning\n",
    "Machine learning models use three primary types of datasets:\n",
    "\n",
    "- **Train Dataset**\n",
    "- **Test Dataset**\n",
    "- **Validation Dataset** (optional)\n",
    "\n",
    "> **Note:** While the validation dataset is optional, training and test datasets are mandatory.\n",
    "\n",
    "## What Are Train and Test Datasets?\n",
    "\n",
    "In machine learning, datasets are typically divided into two main subsets:\n",
    "\n",
    "- **Training Dataset**: Used to train the model, allowing it to learn patterns and relationships in the data.\n",
    "- **Test Dataset**: Used to evaluate the model's performance on unseen data, assessing how well it generalizes.\n",
    "- **Validation Dataset (Optional)**: Used to fine-tune the model, often in hyperparameter tuning.\n",
    "\n",
    "## How to Decide Dataset Sizes\n",
    "There is no strict rule, but experts recommend:\n",
    "\n",
    "| Train Set | Test Set |\n",
    "|-----------|---------|\n",
    "| **70%**   | **30%** |\n",
    "| **60%**   | **40%** |\n",
    "\n",
    "- The exact ratio depends on the size and nature of the dataset, but these proportions are often a good starting point.\n",
    "\n",
    "## Splitting Data Using `train_test_split()`\n",
    "The `train_test_split()` function from `sklearn.model_selection` is used to split datasets into training and testing sets.\n",
    "\n",
    "---\n",
    "\n",
    "## Basic Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434a8d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = np.arange(10)\n",
    "X_train, X_test = train_test_split(dataset, train_size=0.6)\n",
    "\n",
    "print(\"Train Data:\", X_train)\n",
    "print(\"Test Data:\", X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7e263f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Tools and Libraries\n",
    "\n",
    "We'll use the following Python libraries:\n",
    "- **`scikit-learn`**: For dataset splitting, preprocessing, modeling, and cross-validation.\n",
    "- **`pandas`**: For data manipulation and handling structured data.\n",
    "- **`numpy`**: For numerical operations and creating synthetic datasets.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Loading a Dataset\n",
    "\n",
    "Let's start by loading datasets to work with. We'll use the **Iris dataset** for classification examples and the **California Housing dataset** for regression examples, both available in `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4935b334",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris, fetch_california_housing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the Iris dataset (classification)\n",
    "iris = load_iris()\n",
    "X_iris = iris.data  # Features\n",
    "y_iris = iris.target  # Labels\n",
    "\n",
    "# Load the California Housing dataset (regression)\n",
    "housing = fetch_california_housing()\n",
    "X_housing = housing.data  # Features\n",
    "y_housing = housing.target  # Target variable (house prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b283dec8",
   "metadata": {},
   "source": [
    "- **Iris Dataset**: Contains 150 samples with 4 features (sepal/petal length and width) and 3 classes (species).\n",
    "- **California Housing Dataset**: Contains 20,640 samples with 8 features (e.g., house age, number of rooms) and a continuous target (house price).\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Random Splitting\n",
    "The simplest way to split data is **random splitting**, where data is divided randomly into training and test sets. A common ratio is 80% training and 20% testing. The `train_test_split` function from `scikit-learn` makes this easy.\n",
    "\n",
    "### Ensuring Consistency with `random_state`\n",
    "Using `random_state=0` ensures that the same train-test split is obtained across multiple runs.\n",
    "\n",
    "ðŸ’¡ Use 42 as a convention, but any fixed number works! ðŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8226b446",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the Iris dataset (80% train, 20% test)\n",
    "X_train_iris, X_test_iris, y_train_iris, y_test_iris = train_test_split(\n",
    "    X_iris, y_iris, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Iris training set size: {X_train_iris.shape[0]} samples\")\n",
    "print(f\"Iris test set size: {X_test_iris.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a14476f",
   "metadata": {},
   "source": [
    "- **Output** (approximate):\n",
    "  ```\n",
    "  Iris training set size: 120 samples\n",
    "  Iris test set size: 30 samples\n",
    "  ```\n",
    "- **`test_size=0.2`**: 20% of the data goes to the test set.\n",
    "- **`random_state=42`**: Ensures reproducibility.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Stratified Splitting\n",
    "\n",
    "For classification problems, especially with imbalanced datasets, **stratified splitting** ensures that the class distribution is preserved in both training and test sets. The `train_test_split` function supports this via the `stratify` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4123d6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified split for Iris dataset\n",
    "X_train_strat, X_test_strat, y_train_strat, y_test_strat = train_test_split(\n",
    "    X_iris, y_iris, test_size=0.2, stratify=y_iris, random_state=42\n",
    ")\n",
    "\n",
    "# Check class distribution\n",
    "print(\"Original class distribution:\")\n",
    "print(pd.Series(y_iris).value_counts(normalize=True))\n",
    "print(\"Training set class distribution:\")\n",
    "print(pd.Series(y_train_strat).value_counts(normalize=True))\n",
    "print(\"Test set class distribution:\")\n",
    "print(pd.Series(y_test_strat).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8664a6c4",
   "metadata": {},
   "source": [
    "- **Output** (approximate):\n",
    "  ```\n",
    "  Original class distribution:\n",
    "  0    0.333333\n",
    "  1    0.333333\n",
    "  2    0.333333\n",
    "  Name: proportion, dtype: float64\n",
    "  Training set class distribution:\n",
    "  0    0.333333\n",
    "  1    0.333333\n",
    "  2    0.333333\n",
    "  Name: proportion, dtype: float64\n",
    "  Test set class distribution:\n",
    "  0    0.333333\n",
    "  1    0.333333\n",
    "  2    0.333333\n",
    "  Name: proportion, dtype: float64\n",
    "  ```\n",
    "- The proportions remain consistent across splits, which is critical for fair evaluation.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Time-Based Splitting for Time Series Data\n",
    "\n",
    "For **time series data**, random splitting is inappropriate because the temporal order matters. Instead, we split based on time, using earlier data for training and later data for testing.\n",
    "\n",
    "Hereâ€™s an example with a synthetic time series dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb666ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a synthetic time series dataset\n",
    "dates = pd.date_range(start='2020-01-01', periods=100, freq='D')\n",
    "data = pd.DataFrame({\n",
    "    'feature1': np.random.randn(100),\n",
    "    'feature2': np.random.randn(100),\n",
    "    'target': np.random.randn(100)\n",
    "}, index=dates)\n",
    "\n",
    "# Split: first 80 days for training, last 20 for testing\n",
    "train_size = 80\n",
    "X_time = data[['feature1', 'feature2']]\n",
    "y_time = data['target']\n",
    "X_train_time = X_time.iloc[:train_size]\n",
    "X_test_time = X_time.iloc[train_size:]\n",
    "y_train_time = y_time.iloc[:train_size]\n",
    "y_test_time = y_time.iloc[train_size:]\n",
    "\n",
    "print(f\"Time-based training set size: {X_train_time.shape[0]} samples\")\n",
    "print(f\"Time-based test set size: {X_test_time.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9511fab",
   "metadata": {},
   "source": [
    "- **Output**:\n",
    "  ```\n",
    "  Time-based training set size: 80 samples\n",
    "  Time-based test set size: 20 samples\n",
    "  ```\n",
    "- The split preserves the temporal sequence, mimicking real-world forecasting scenarios.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Cross-Validation\n",
    "\n",
    "**Cross-validation** provides a robust estimate of model performance by splitting the data into multiple \"folds\" and training/testing the model multiple times. Common methods include `KFold` (for regression) and `StratifiedKFold` (for classification).\n",
    "\n",
    "**K-Fold Cross Validation** solves the limitations of a single train-test split by splitting the dataset into **K** equal-sized folds. The model is trained and evaluated **K** times, ensuring every data point is used for both training and validation.\n",
    "\n",
    "### How K-Fold Works\n",
    "1. Divide the dataset into **K** equal-sized subsets (folds).\n",
    "2. Use **one** fold as the validation set and the remaining **K-1** folds for training.\n",
    "3. Train and evaluate the model.\n",
    "4. Repeat the process **K** times, each time using a different fold as the validation set.\n",
    "5. Compute the average of all K iterations to get a final performance score.\n",
    "\n",
    "### Advantages of K-Fold Cross Validation\n",
    "- Reduces **bias** and **variance**.\n",
    "- Ensures **every data point** is used for both training and validation.\n",
    "- Provides a **more accurate estimate** of model performance.\n",
    "- Avoids **overfitting** compared to a simple train-test split.\n",
    "\n",
    "### 5.1. Stratified K-Fold for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780b359f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define the model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define StratifiedKFold (5 folds)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate model using K-Fold\n",
    "accuracies = cross_val_score(model, X_iris, y_iris, cv=skf)\n",
    "\n",
    "print(f\"Cross-validation accuracies: {accuracies}\")\n",
    "print(f\"Mean accuracy: {np.mean(accuracies):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c286712",
   "metadata": {},
   "source": [
    "- **Output** (example):\n",
    "  ```\n",
    "  Cross-validation accuracies: [0.9667, 0.9333, 0.9667, 0.9667, 1.0]\n",
    "  Mean accuracy: 0.97\n",
    "  ```\n",
    "- Each fold uses a different test set, and the mean accuracy reflects overall performance.\n",
    "\n",
    "### 5.2. K-Fold for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1848519a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Define KFold (5 folds)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Train and evaluate model using K-Fold\n",
    "scores = cross_val_score(model, X_housing, y_housing, cv=kf)\n",
    "\n",
    "# Perform cross-validation on California Housing dataset\n",
    "\n",
    "print(f\"Cross-validation MSEs: {scores}\")\n",
    "print(f\"Mean MSE: {np.mean(scores):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d86dbf",
   "metadata": {},
   "source": [
    "- **Output** (example):\n",
    "  ```\n",
    "  Accuracy with pipeline: 0.97\n",
    "  ```\n",
    "- The pipeline ensures that scaling is applied consistently, avoiding manual errors.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary of Methods and Tools\n",
    "\n",
    "| **Method**            | **Tool/Function**           | **Use Case**                          | **Key Feature**                     |\n",
    "|-----------------------|-----------------------------|---------------------------------------|-------------------------------------|\n",
    "| Random Split          | `train_test_split`          | General-purpose splitting            | Simple, fast                        |\n",
    "| Stratified Split      | `train_test_split(stratify)`| Classification with imbalanced data  | Preserves class distribution        |\n",
    "| Time-Based Split      | Manual (e.g., pandas)       | Time series data                     | Maintains temporal order            |\n",
    "| Cross-Validation      | `KFold`, `StratifiedKFold`  | Robust performance estimation        | Multiple train/test splits          |\n",
    "| Preprocessing         | `StandardScaler`, `Pipeline`| Feature scaling, avoiding leakage    | Safe preprocessing application      |\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This guide has covered the essentials of handling train and test datasets in Python:\n",
    "- **Loading datasets** using `scikit-learn`.\n",
    "- **Splitting methods**: Random, stratified, time-based, and cross-validation.\n",
    "- **Preprocessing**: Proper techniques to avoid data leakage using scalers and pipelines.\n",
    "- **Examples**: Practical code for classification (Iris), regression (California Housing), and time series data.\n",
    "\n",
    "---\n",
    "\n",
    "## Cross-Validation and Pipelines\n",
    "\n",
    "### Why Use a Pipeline?\n",
    "- Ensures preprocessing occurs **after** each cross-validation split.\n",
    "- Prevents **data leakage**.\n",
    "\n",
    "### Cross-Validate a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f4e099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "df = pd.read_csv('http://bit.ly/kaggletrain')\n",
    "X = df[['Sex', 'Name']]\n",
    "y = df['Survived']\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "vect = CountVectorizer()\n",
    "ct = make_column_transformer((ohe, ['Sex']), (vect, 'Name'))\n",
    "clf = LogisticRegression(solver='liblinear', random_state=1)\n",
    "pipe = make_pipeline(ct, clf)\n",
    "\n",
    "cross_val_score(pipe, X, y, cv=5, scoring='accuracy').mean()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
